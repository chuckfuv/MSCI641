{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pj5Xqd7BiosS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27498,
     "status": "ok",
     "timestamp": 1564065769270,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "v9Taemwqiq2g",
    "outputId": "d98f613a-9d0b-48b5-8f08-25e07c4a9c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4360,
     "status": "ok",
     "timestamp": 1564065771709,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "DMvGXCpNi9Ut",
    "outputId": "01902eb8-cf98-4236-f100-62e8eebec13f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  project.zip\n",
      "  inflating: LICENSE                 \n",
      " extracting: scores                  \n",
      "  inflating: test_bodies.csv         \n",
      "   creating: __MACOSX/\n",
      "  inflating: __MACOSX/._test_bodies.csv  \n",
      "   creating: utils/\n",
      "  inflating: utils/generate_test_splits.py  \n",
      "   creating: __MACOSX/utils/\n",
      "  inflating: __MACOSX/utils/._generate_test_splits.py  \n",
      "  inflating: utils/system.py         \n",
      "  inflating: __MACOSX/utils/._system.py  \n",
      " extracting: utils/__init__.py       \n",
      "   creating: utils/__pycache__/\n",
      "  inflating: utils/__pycache__/dataset.cpython-36.pyc  \n",
      "  inflating: utils/__pycache__/generate_test_splits.cpython-36.pyc  \n",
      "  inflating: utils/__pycache__/score.cpython-36.pyc  \n",
      "  inflating: utils/__pycache__/system.cpython-36.pyc  \n",
      "  inflating: utils/__pycache__/__init__.cpython-36.pyc  \n",
      "  inflating: utils/dataset.py        \n",
      "  inflating: __MACOSX/utils/._dataset.py  \n",
      "  inflating: utils/score.py          \n",
      "  inflating: __MACOSX/utils/._score.py  \n",
      "  inflating: competition_test_stances.csv  \n",
      "  inflating: __MACOSX/._competition_test_stances.csv  \n",
      "   creating: __pycache__/\n",
      "  inflating: __pycache__/feature_engineering.cpython-36.pyc  \n",
      "  inflating: train_bodies.csv        \n",
      "  inflating: __MACOSX/._train_bodies.csv  \n",
      "   creating: fnc-1/\n",
      "  inflating: fnc-1/competition_test_stances_unlabeled.csv  \n",
      "  inflating: fnc-1/test_bodies.csv   \n",
      "  inflating: fnc-1/competition_test_stances.csv  \n",
      "   creating: __MACOSX/fnc-1/\n",
      "  inflating: __MACOSX/fnc-1/._competition_test_stances.csv  \n",
      "  inflating: fnc-1/train_bodies.csv  \n",
      "  inflating: fnc-1/README.md         \n",
      "  inflating: fnc-1/test_stances_unlabeled.csv  \n",
      "  inflating: __MACOSX/fnc-1/._test_stances_unlabeled.csv  \n",
      "  inflating: fnc-1/competition_test_bodies.csv  \n",
      "  inflating: __MACOSX/fnc-1/._competition_test_bodies.csv  \n",
      "  inflating: fnc-1/train_stances.random.csv  \n",
      "  inflating: fnc-1/train_stances.csv  \n",
      "  inflating: fnc-1/scorer.py         \n",
      "  inflating: baseline.ipynb          \n",
      "  inflating: test_stances_unlabeled.csv  \n",
      "  inflating: __MACOSX/._test_stances_unlabeled.csv  \n",
      "  inflating: competition_test_bodies.csv  \n",
      "  inflating: __MACOSX/._competition_test_bodies.csv  \n",
      "  inflating: train_stances.csv       \n",
      "  inflating: __MACOSX/._train_stances.csv  \n",
      "   creating: splits/\n",
      " extracting: splits/dummy.txt        \n",
      "  inflating: splits/training_ids.txt  \n",
      "  inflating: splits/hold_out_ids.txt  \n"
     ]
    }
   ],
   "source": [
    "! unzip project.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4msXk4oLjAnN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from gensim.models import Word2Vec\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional, Flatten\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import callbacks, regularizers\n",
    "from utils.dataset import DataSet\n",
    "from utils.generate_test_splits import train_vali_split, get_stances_for_folds\n",
    "from utils.score import report_score, LABELS, score_submission\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from utils.system import parse_params, check_version\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sN-0wDufjNXb"
   },
   "outputs": [],
   "source": [
    "LSTM_DIM = 300\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1718,
     "status": "ok",
     "timestamp": 1564065776953,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "yCzQNq6WjQID",
    "outputId": "1be2966e-7ca8-4b4c-d6b9-bc81a38ffef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n",
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load the training dataset and generate folds\n",
    "d = DataSet()\n",
    "training, hold_out = train_vali_split(d)\n",
    "training_stances, hold_out_stances = get_stances_for_folds(d,training,hold_out)\n",
    "# Load the competition dataset\n",
    "competition_dataset = DataSet(\"competition_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwE6fcXnjSlh"
   },
   "outputs": [],
   "source": [
    "def prepareData(dataset, stances):\n",
    "    headline = []\n",
    "    body = []\n",
    "    stanceFinal = []\n",
    "    for stance in stances:\n",
    "        headline.append(stance['Headline'])\n",
    "        body.append(dataset.articles[stance['Body ID']])\n",
    "        stanceFinal.append(stance['Stance'])\n",
    "    return headline, body, stanceFinal\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enH8Dz8XjU3W"
   },
   "outputs": [],
   "source": [
    "train_headline, train_body, train_stanceFinal = prepareData(d, training_stances)\n",
    "hold_out_headline, hold_out_body, hold_out_stanceFinal = prepareData(d, hold_out_stances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKO_ez-yjW-f"
   },
   "outputs": [],
   "source": [
    "competition_headline, competition_body, competition_stanceFinal = prepareData(competition_dataset, competition_dataset.stances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wYw9VNfkibR"
   },
   "outputs": [],
   "source": [
    "def stance_to_onehot(stance):\n",
    "    li = []\n",
    "    LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
    "    for i in stance:\n",
    "        if i == LABELS[0]:\n",
    "            li.append([1,0,0,0])\n",
    "        elif i == LABELS[1]:\n",
    "            li.append([0,1,0,0])\n",
    "        elif i == LABELS[2]:\n",
    "            li.append([0,0,1,0])\n",
    "        elif i == LABELS[3]:\n",
    "            li.append([0,0,0,1])\n",
    "    return np.array(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "909MSpeCklPC"
   },
   "outputs": [],
   "source": [
    "competition_stance_onehot = stance_to_onehot(competition_stanceFinal)\n",
    "train_stance_onehot = stance_to_onehot(train_stanceFinal)\n",
    "hold_out_stance_onehot = stance_to_onehot(hold_out_stanceFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8u7-tw3jguZ"
   },
   "outputs": [],
   "source": [
    "token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "def get_tokens(line,\n",
    "                    token_pattern=token_pattern):\n",
    "    token_pattern = re.compile(token_pattern, flags = re.UNICODE)\n",
    "    tokens = [x.lower() for x in token_pattern.findall(line)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPuSAofCjbPl"
   },
   "outputs": [],
   "source": [
    "train_headline = [get_tokens(text) for text in train_headline]\n",
    "hold_out_headline = [get_tokens(text) for text in hold_out_headline]\n",
    "train_body = [get_tokens(text) for text in train_body]\n",
    "hold_out_body = [get_tokens(text) for text in hold_out_body]\n",
    "competition_headline = [get_tokens(text) for text in competition_headline]\n",
    "competition_body = [get_tokens(text) for text in competition_body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjeKzXDyr6M4"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "corpus = train_headline+train_body+hold_out_headline+hold_out_body+competition_headline+competition_body\n",
    "tokenizer.fit_on_texts([' '.join(seq) for seq in corpus])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29677,
     "status": "ok",
     "timestamp": 1563276554758,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "nV_E_3nU5TA5",
    "outputId": "164304eb-4651-4d2c-b581-b410cebaa219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29419"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GV3LnpnmCob"
   },
   "outputs": [],
   "source": [
    "train_headline = tokenizer.texts_to_sequences(train_headline)\n",
    "train_body = tokenizer.texts_to_sequences(train_body)\n",
    "hold_out_headline = tokenizer.texts_to_sequences(hold_out_headline)\n",
    "hold_out_body = tokenizer.texts_to_sequences(hold_out_body)\n",
    "competition_headline = tokenizer.texts_to_sequences(competition_headline)\n",
    "competition_body = tokenizer.texts_to_sequences(competition_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40715,
     "status": "ok",
     "timestamp": 1564065838473,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "wQNJGOEcmRBc",
    "outputId": "29cfd9e1-1389-48f7-a86a-3df14b6d2193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th Percentile body Length: 101\n"
     ]
    }
   ],
   "source": [
    "MAX_BODY_LENGTH = int(np.percentile([len(doc) for doc in train_body+hold_out_body+competition_body],10))\n",
    "\n",
    "print('10th Percentile body Length:', MAX_BODY_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39699,
     "status": "ok",
     "timestamp": 1564065838473,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "_sUXxySVmV5R",
    "outputId": "2e500bdd-cc4d-4dc1-d31d-b7234a7030f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th Percentile headline Length: 16\n",
      "90th Percentile body Length: 361\n"
     ]
    }
   ],
   "source": [
    "MAX_HEADLINE_LENGTH = int(np.percentile([len(doc) for doc in train_headline+hold_out_headline], 90))\n",
    "\n",
    "print('90th Percentile headline Length:', MAX_HEADLINE_LENGTH)\n",
    "MAX_HEADLINE_LENGTH =15\n",
    "MAX_BODY_LENGTH = int(np.mean([len(doc) for doc in train_body+hold_out_body]))\n",
    "\n",
    "print('90th Percentile body Length:', MAX_BODY_LENGTH)\n",
    "MAX_BODY_TRUNC = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHbMlOnhmb-U"
   },
   "outputs": [],
   "source": [
    "train_headline = pad_sequences(train_headline, maxlen=MAX_HEADLINE_LENGTH, padding='post', truncating='post')\n",
    "hold_out_headline = pad_sequences(hold_out_headline, maxlen=MAX_HEADLINE_LENGTH, padding='post', truncating='post')\n",
    "train_first_body = pad_sequences(train_body, maxlen=MAX_BODY_TRUNC, padding='post', truncating='post')\n",
    "train_last_body = pad_sequences(train_body, maxlen=MAX_BODY_TRUNC, padding='post', truncating='pre')\n",
    "hold_out_first_body = pad_sequences(hold_out_body, maxlen=MAX_BODY_TRUNC, padding='post', truncating='post')\n",
    "hold_out_last_body = pad_sequences(hold_out_body, maxlen=MAX_BODY_TRUNC, padding='post', truncating='pre')\n",
    "competition_headline = pad_sequences(competition_headline, maxlen=MAX_HEADLINE_LENGTH, padding='post', truncating='post')\n",
    "competition_first_body = pad_sequences(competition_body, maxlen=MAX_BODY_TRUNC, padding='post', truncating='post')\n",
    "competition_last_body = pad_sequences(competition_body, maxlen=MAX_BODY_TRUNC, padding='post', truncating='pre')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 191740,
     "status": "ok",
     "timestamp": 1564065993716,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "vQpO3KhIp4im",
    "outputId": "1f1b75ee-1ed2-4d9d-be0b-c2b06cb2910c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.42B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "del embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhFY4Ambp-dx"
   },
   "outputs": [],
   "source": [
    "def builtWeightSharingModel(drop_out_rate=0.5,dense_neuron = 32):\n",
    "    headline_input = Input(shape=(MAX_HEADLINE_LENGTH,), name='headline_input')\n",
    "    first_body_input = Input(shape=(MAX_BODY_TRUNC,), name='first_body_input')\n",
    "    last_body_input = Input(shape=(MAX_BODY_TRUNC,), name='last_body_input')\n",
    "    e = Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embedding_matrix], trainable=False, name='headline_word_embedding_layer', \n",
    "                          mask_zero=True)\n",
    "    headline_embedding = e(headline_input)\n",
    "    first_body_embedding = e(first_body_input)\n",
    "    last_body_embedding = e(last_body_input)\n",
    "    encoder_outputs, state_h, state_c = LSTM(LSTM_DIM, return_sequences=False, return_state = True,dropout=0.5,recurrent_dropout = 0.5, name='lstm_layer_encoder')(headline_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    decoder = LSTM(LSTM_DIM, return_sequences=False, return_state = True,dropout=0.5,recurrent_dropout = 0.5, name='lstm_layer_first_body')\n",
    "    first_body_outputs, _, _ = decoder(first_body_embedding, initial_state=encoder_states)\n",
    "    last_body_outputs, _, _ = decoder(last_body_embedding, initial_state=encoder_states)\n",
    "    x = tf.keras.layers.concatenate([first_body_outputs, last_body_outputs])\n",
    "    x = Dropout(rate=drop_out_rate, name='dropout_0')(x)\n",
    "    #x = Dense(dense_neuron, activation='relu')(x)\n",
    "    #x = Dropout(rate=drop_out_rate, name='dropout_1')(x)\n",
    "    #x = Dense(dense_neuron, activation='relu')(x)\n",
    "    #x = Dropout(rate=drop_out_rate, name='dropout_2')(x)\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(4, activation='softmax', name='main_output')(x)\n",
    "    model = Model(inputs=[headline_input, first_body_input, last_body_input], outputs=main_output)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiQTi9I8wXtC"
   },
   "outputs": [],
   "source": [
    "def builtConditionalModel(drop_out_rate=0.5,dense_neuron = 32):\n",
    "    headline_input = Input(shape=(MAX_HEADLINE_LENGTH,), name='headline_input')\n",
    "    first_body_input = Input(shape=(MAX_BODY_TRUNC,), name='first_body_input')\n",
    "    #last_body_input = Input(shape=(MAX_BODY_TRUNC,), name='last_body_input')\n",
    "    e = Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embedding_matrix], trainable=False, name='headline_word_embedding_layer', \n",
    "                          mask_zero=True)\n",
    "    headline_embedding = e(headline_input)\n",
    "    first_body_embedding = e(first_body_input)\n",
    "    #last_body_embedding = e(last_body_input)\n",
    "    encoder_outputs, state_h, state_c = LSTM(LSTM_DIM, return_sequences=False, return_state = True,dropout=0.5,recurrent_dropout = 0.5, name='lstm_layer_encoder')(headline_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    decoder = LSTM(LSTM_DIM, return_sequences=False, return_state = True,dropout=0.5,recurrent_dropout = 0.5, name='lstm_layer_first_body')\n",
    "    first_body_outputs, _, _ = decoder(first_body_embedding, initial_state=encoder_states)\n",
    "    #last_body_outputs, _, _ = decoder(last_body_embedding, initial_state=encoder_states)\n",
    "    #x = tf.keras.layers.concatenate([first_body_outputs, last_body_outputs])\n",
    "    x = Dropout(rate=drop_out_rate, name='dropout_0')(first_body_outputs)\n",
    "    #x = Dense(dense_neuron, activation='relu')(x)\n",
    "    #x = Dropout(rate=drop_out_rate, name='dropout_1')(x)\n",
    "    #x = Dense(dense_neuron, activation='relu')(x)\n",
    "    #x = Dropout(rate=drop_out_rate, name='dropout_2')(x)\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(4, activation='softmax', name='main_output')(x)\n",
    "    model = Model(inputs=[headline_input, first_body_input], outputs=main_output)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQrwXe7DvsHo"
   },
   "outputs": [],
   "source": [
    "def builtCompositeModel(drop_out_rate=0.5,dense_neuron = 32):\n",
    "    headline_input = Input(shape=(MAX_HEADLINE_LENGTH,), name='headline_input')\n",
    "    first_body_input = Input(shape=(MAX_BODY_TRUNC,), name='first_body_input')\n",
    "    last_body_input = Input(shape=(MAX_BODY_TRUNC,), name='last_body_input')\n",
    "    headline_embedding = Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embedding_matrix], trainable=False, name='headline_word_embedding_layer', \n",
    "                          mask_zero=True)(headline_input)\n",
    "    first_body_embedding = Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embedding_matrix], trainable=False, name='first_body_word_embedding_layer', \n",
    "                          mask_zero=True)(first_body_input)\n",
    "    last_body_embedding = Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                          output_dim=EMBEDDING_DIM,\n",
    "                          weights = [embedding_matrix], trainable=False, name='last_bodyword_embedding_layer', \n",
    "                          mask_zero=True)(last_body_input)\n",
    "    encoder_outputs, state_h, state_c = LSTM(LSTM_DIM, return_sequences=False, return_state = True,dropout=0.5,recurrent_dropout = 0.5, name='lstm_layer_encoder')(headline_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    first_body_outputs, _, _ = LSTM(LSTM_DIM, return_sequences=False, return_state = True,dropout=0.5,recurrent_dropout = 0.5, name='lstm_layer_first_body')(first_body_embedding, initial_state=encoder_states)\n",
    "    last_body_outputs, _, _ = LSTM(LSTM_DIM, return_sequences=False, return_state = True,dropout=0.5,recurrent_dropout = 0.5, name='lstm_layer_last_body')(last_body_embedding, initial_state=encoder_states)\n",
    "    x = tf.keras.layers.concatenate([first_body_outputs, last_body_outputs])\n",
    "    x = Dropout(rate=drop_out_rate, name='dropout_1')(x)\n",
    "    #x = Dense(dense_neuron, activation='relu')(x)\n",
    "    #x = Dropout(rate=drop_out_rate, name='dropout_1')(x)\n",
    "    #x = Dense(dense_neuron, activation='relu')(x)\n",
    "    #x = Dropout(rate=drop_out_rate, name='dropout_2')(x)\n",
    "\n",
    "    # And finally we add the main logistic regression layer\n",
    "    main_output = Dense(4, activation='softmax', name='main_output')(x)\n",
    "    model = Model(inputs=[headline_input, first_body_input, last_body_input], outputs=main_output)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWhWNEeGqLq4"
   },
   "outputs": [],
   "source": [
    "def trainModel(model,train_input,vali_input, batch=128,ep=50):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    output_directory = ''\n",
    "    model_checkpoint = callbacks.ModelCheckpoint(os.path.join(output_directory , 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'),save_best_only=True,mode='auto',period=10)\n",
    "    '''\n",
    "    model.fit([np.concatenate((train_headline, hold_out_headline), axis=0), np.concatenate((train_first_body, hold_out_first_body), axis=0), np.concatenate((train_last_body, hold_out_last_body), axis=0)], np.concatenate((train_stance_onehot, hold_out_stance_onehot), axis=0),\n",
    "          batch_size=batch,\n",
    "          epochs=ep,\n",
    "          validation_data=([competition_headline, competition_first_body, competition_last_body], competition_stance_onehot),callbacks=[model_checkpoint])\n",
    "    '''\n",
    "    model.fit(train_input, train_stance_onehot,\n",
    "          batch_size=batch,\n",
    "          epochs=ep,\n",
    "          validation_data=(vali_input, hold_out_stance_onehot),callbacks=[model_checkpoint])\n",
    "    #'''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4887,
     "status": "ok",
     "timestamp": 1564074270496,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "mF-pvnoPqEQD",
    "outputId": "e63b922e-b0fe-4655-9104-a21806580c8d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8bf38e66be92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuiltWeightSharingModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_out_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_headline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_first_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_last_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhold_out_headline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_out_first_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_out_last_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainModel' is not defined"
     ]
    }
   ],
   "source": [
    "model = trainModel(builtWeightSharingModel(drop_out_rate=0.5),[train_headline, train_first_body, train_last_body],[hold_out_headline, hold_out_first_body, hold_out_last_body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2229090,
     "status": "ok",
     "timestamp": 1564023396294,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "uD9qcX-3y3WI",
    "outputId": "d51fcb33-49b9-458d-ba2c-d9cb1f71a220"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 17:20:33.336267 139669666088832 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40350 samples, validate on 9622 samples\n",
      "Epoch 1/50\n",
      "40350/40350 [==============================] - 87s 2ms/sample - loss: 0.2969 - acc: 0.8879 - val_loss: 0.5554 - val_acc: 0.7986\n",
      "Epoch 2/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2971 - acc: 0.8865 - val_loss: 0.5357 - val_acc: 0.8021\n",
      "Epoch 3/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2958 - acc: 0.8888 - val_loss: 0.5294 - val_acc: 0.8060\n",
      "Epoch 4/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2895 - acc: 0.8910 - val_loss: 0.5047 - val_acc: 0.8138\n",
      "Epoch 5/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2912 - acc: 0.8911 - val_loss: 0.5147 - val_acc: 0.8084\n",
      "Epoch 6/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2855 - acc: 0.8929 - val_loss: 0.5326 - val_acc: 0.8034\n",
      "Epoch 7/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2840 - acc: 0.8932 - val_loss: 0.5349 - val_acc: 0.8034\n",
      "Epoch 8/50\n",
      "40350/40350 [==============================] - 84s 2ms/sample - loss: 0.2842 - acc: 0.8941 - val_loss: 0.5039 - val_acc: 0.8174\n",
      "Epoch 9/50\n",
      "40350/40350 [==============================] - 84s 2ms/sample - loss: 0.2806 - acc: 0.8965 - val_loss: 0.5259 - val_acc: 0.8107\n",
      "Epoch 10/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2819 - acc: 0.8943 - val_loss: 0.5271 - val_acc: 0.8123\n",
      "Epoch 11/50\n",
      "40350/40350 [==============================] - 85s 2ms/sample - loss: 0.2787 - acc: 0.8968 - val_loss: 0.5066 - val_acc: 0.8183\n",
      "Epoch 12/50\n",
      "40350/40350 [==============================] - 84s 2ms/sample - loss: 0.2726 - acc: 0.8969 - val_loss: 0.5115 - val_acc: 0.8171\n",
      "Epoch 13/50\n",
      "40192/40350 [============================>.] - ETA: 0s - loss: 0.2726 - acc: 0.8970"
     ]
    }
   ],
   "source": [
    "model = trainModel(model,[train_headline, train_first_body, train_last_body],[hold_out_headline, hold_out_first_body, hold_out_last_body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSz6e0YZB6E3"
   },
   "outputs": [],
   "source": [
    "def y_to_stance(onehot):\n",
    "    LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
    "    return [LABELS[index] for index in onehot]\n",
    "\n",
    "def evaluate(predicted, actual):\n",
    "    \n",
    "    predicted = y_to_stance(predicted)\n",
    "    print(\"Scores on the test set\")\n",
    "    report_score(actual,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfntWNsyeM_e"
   },
   "outputs": [],
   "source": [
    "model.save('weight_sharing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105116,
     "status": "ok",
     "timestamp": 1564075218760,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "78YIQQj-B-XX",
    "outputId": "4da62b9f-8f15-4a96-fc3c-c682df63ca68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight sharing\n",
      "Scores on the test set\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    386    |     2     |    239    |    135    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    86     |     1     |    60     |    15     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    145    |     8     |   1382    |    265    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    466    |     0     |    437    |   5995    |\n",
      "-------------------------------------------------------------\n",
      "Score: 3402.75 out of 4448.5\t(76.49207598066764%)\n",
      "Scores on the test set\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    813    |     1     |    288    |    801    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    240    |     4     |    77     |    376    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    662    |     0     |   1930    |   1872    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |   1738    |     0     |   1034    |   15577   |\n",
      "-------------------------------------------------------------\n",
      "Score: 6958.25 out of 11651.25\t(59.721059972106%)\n"
     ]
    }
   ],
   "source": [
    "print('weight sharing')\n",
    "pred = model.predict([hold_out_headline, hold_out_first_body,hold_out_last_body])\n",
    "y_classes = pred.argmax(axis=-1)\n",
    "actual = hold_out_stanceFinal\n",
    "evaluate(y_classes, actual)\n",
    "\n",
    "pred = model.predict([competition_headline, competition_first_body,competition_last_body])\n",
    "y_classes = pred.argmax(axis=-1)\n",
    "actual = competition_stanceFinal\n",
    "evaluate(y_classes, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5321,
     "status": "ok",
     "timestamp": 1563930415670,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "MZmbFZ7GyyW7",
    "outputId": "37e15924-0df1-445f-9b47-fd84818b86ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 23:09:45.756192 140532354664320 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "headline_input (InputLayer)     [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_body_input (InputLayer)   [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "headline_word_embedding_layer ( (None, 15, 300)      8825700     headline_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "last_body_input (InputLayer)    [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "first_body_word_embedding_layer (None, 50, 300)      8825700     first_body_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer_encoder (LSTM)       [(None, 300), (None, 721200      headline_word_embedding_layer[0][\n",
      "__________________________________________________________________________________________________\n",
      "last_bodyword_embedding_layer ( (None, 50, 300)      8825700     last_body_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer_first_body (LSTM)    [(None, 300), (None, 721200      first_body_word_embedding_layer[0\n",
      "                                                                 lstm_layer_encoder[0][1]         \n",
      "                                                                 lstm_layer_encoder[0][2]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer_last_body (LSTM)     [(None, 300), (None, 721200      last_bodyword_embedding_layer[0][\n",
      "                                                                 lstm_layer_encoder[0][1]         \n",
      "                                                                 lstm_layer_encoder[0][2]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 600)          0           lstm_layer_first_body[0][0]      \n",
      "                                                                 lstm_layer_last_body[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 600)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 4)            2404        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,643,104\n",
      "Trainable params: 2,166,004\n",
      "Non-trainable params: 26,477,100\n",
      "__________________________________________________________________________________________________\n",
      "Train on 40350 samples, validate on 9622 samples\n",
      "Epoch 1/400\n",
      "40350/40350 [==============================] - 19s 461us/sample - loss: 0.8398 - acc: 0.7159 - val_loss: 0.8249 - val_acc: 0.7169\n",
      "Epoch 2/400\n",
      "40350/40350 [==============================] - 16s 400us/sample - loss: 0.7472 - acc: 0.7376 - val_loss: 0.8240 - val_acc: 0.7082\n",
      "Epoch 3/400\n",
      "40350/40350 [==============================] - 16s 397us/sample - loss: 0.7188 - acc: 0.7432 - val_loss: 0.8173 - val_acc: 0.7063\n",
      "Epoch 4/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.6957 - acc: 0.7504 - val_loss: 0.8068 - val_acc: 0.7217\n",
      "Epoch 5/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.6638 - acc: 0.7614 - val_loss: 0.8098 - val_acc: 0.6851\n",
      "Epoch 6/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.6340 - acc: 0.7732 - val_loss: 0.7618 - val_acc: 0.7020\n",
      "Epoch 7/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.5979 - acc: 0.7860 - val_loss: 0.7207 - val_acc: 0.7164\n",
      "Epoch 8/400\n",
      "40350/40350 [==============================] - 16s 395us/sample - loss: 0.5576 - acc: 0.7943 - val_loss: 0.6924 - val_acc: 0.7357\n",
      "Epoch 9/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.5205 - acc: 0.8041 - val_loss: 0.6618 - val_acc: 0.7347\n",
      "Epoch 10/400\n",
      "40350/40350 [==============================] - 18s 445us/sample - loss: 0.4807 - acc: 0.8177 - val_loss: 0.6353 - val_acc: 0.7454\n",
      "Epoch 11/400\n",
      "40350/40350 [==============================] - 16s 395us/sample - loss: 0.4445 - acc: 0.8293 - val_loss: 0.6045 - val_acc: 0.7565\n",
      "Epoch 12/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.4162 - acc: 0.8382 - val_loss: 0.6046 - val_acc: 0.7464\n",
      "Epoch 13/400\n",
      "40350/40350 [==============================] - 16s 395us/sample - loss: 0.3914 - acc: 0.8496 - val_loss: 0.5676 - val_acc: 0.7780\n",
      "Epoch 14/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.3700 - acc: 0.8585 - val_loss: 0.6224 - val_acc: 0.7420\n",
      "Epoch 15/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.3520 - acc: 0.8654 - val_loss: 0.5734 - val_acc: 0.7815\n",
      "Epoch 16/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.3262 - acc: 0.8742 - val_loss: 0.5569 - val_acc: 0.7900\n",
      "Epoch 17/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.3140 - acc: 0.8808 - val_loss: 0.5655 - val_acc: 0.7847\n",
      "Epoch 18/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.3029 - acc: 0.8842 - val_loss: 0.5441 - val_acc: 0.7907\n",
      "Epoch 19/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.2807 - acc: 0.8923 - val_loss: 0.5752 - val_acc: 0.7841\n",
      "Epoch 20/400\n",
      "40350/40350 [==============================] - 16s 398us/sample - loss: 0.2689 - acc: 0.8961 - val_loss: 0.5521 - val_acc: 0.8006\n",
      "Epoch 21/400\n",
      "40350/40350 [==============================] - 16s 396us/sample - loss: 0.2565 - acc: 0.9036 - val_loss: 0.5611 - val_acc: 0.7936\n",
      "Epoch 22/400\n",
      "40350/40350 [==============================] - 16s 395us/sample - loss: 0.2437 - acc: 0.9084 - val_loss: 0.5507 - val_acc: 0.8091\n",
      "Epoch 23/400\n",
      "40350/40350 [==============================] - 16s 395us/sample - loss: 0.2288 - acc: 0.9129 - val_loss: 0.5256 - val_acc: 0.8198\n",
      "Epoch 24/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.2185 - acc: 0.9177 - val_loss: 0.5408 - val_acc: 0.8234\n",
      "Epoch 25/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.2126 - acc: 0.9202 - val_loss: 0.5272 - val_acc: 0.8233\n",
      "Epoch 26/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.2031 - acc: 0.9247 - val_loss: 0.5197 - val_acc: 0.8233\n",
      "Epoch 27/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1931 - acc: 0.9257 - val_loss: 0.5432 - val_acc: 0.8211\n",
      "Epoch 28/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1902 - acc: 0.9289 - val_loss: 0.5234 - val_acc: 0.8303\n",
      "Epoch 29/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1800 - acc: 0.9314 - val_loss: 0.5423 - val_acc: 0.8362\n",
      "Epoch 30/400\n",
      "40350/40350 [==============================] - 16s 399us/sample - loss: 0.1797 - acc: 0.9316 - val_loss: 0.5485 - val_acc: 0.8247\n",
      "Epoch 31/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.1702 - acc: 0.9360 - val_loss: 0.5718 - val_acc: 0.8235\n",
      "Epoch 32/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1612 - acc: 0.9400 - val_loss: 0.5629 - val_acc: 0.8336\n",
      "Epoch 33/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.1572 - acc: 0.9415 - val_loss: 0.5468 - val_acc: 0.8364\n",
      "Epoch 34/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.1532 - acc: 0.9422 - val_loss: 0.5621 - val_acc: 0.8328\n",
      "Epoch 35/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1470 - acc: 0.9432 - val_loss: 0.5399 - val_acc: 0.8427\n",
      "Epoch 36/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.1439 - acc: 0.9460 - val_loss: 0.5385 - val_acc: 0.8370\n",
      "Epoch 37/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.1384 - acc: 0.9470 - val_loss: 0.5752 - val_acc: 0.8372\n",
      "Epoch 38/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.1335 - acc: 0.9496 - val_loss: 0.5431 - val_acc: 0.8482\n",
      "Epoch 39/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1334 - acc: 0.9492 - val_loss: 0.5278 - val_acc: 0.8475\n",
      "Epoch 40/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1265 - acc: 0.9512 - val_loss: 0.5655 - val_acc: 0.8458\n",
      "Epoch 41/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1244 - acc: 0.9544 - val_loss: 0.5921 - val_acc: 0.8326\n",
      "Epoch 42/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.1219 - acc: 0.9533 - val_loss: 0.5523 - val_acc: 0.8495\n",
      "Epoch 43/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1207 - acc: 0.9537 - val_loss: 0.5703 - val_acc: 0.8402\n",
      "Epoch 44/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1153 - acc: 0.9565 - val_loss: 0.5739 - val_acc: 0.8465\n",
      "Epoch 45/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1139 - acc: 0.9570 - val_loss: 0.5566 - val_acc: 0.8533\n",
      "Epoch 46/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.1115 - acc: 0.9572 - val_loss: 0.5813 - val_acc: 0.8411\n",
      "Epoch 47/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.1077 - acc: 0.9577 - val_loss: 0.5725 - val_acc: 0.8418\n",
      "Epoch 48/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.1080 - acc: 0.9595 - val_loss: 0.5345 - val_acc: 0.8525\n",
      "Epoch 49/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1064 - acc: 0.9602 - val_loss: 0.5757 - val_acc: 0.8453\n",
      "Epoch 50/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.1016 - acc: 0.9608 - val_loss: 0.5692 - val_acc: 0.8487\n",
      "Epoch 51/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.1035 - acc: 0.9600 - val_loss: 0.5891 - val_acc: 0.8454\n",
      "Epoch 52/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.1006 - acc: 0.9609 - val_loss: 0.5527 - val_acc: 0.8490\n",
      "Epoch 53/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0970 - acc: 0.9626 - val_loss: 0.5691 - val_acc: 0.8501\n",
      "Epoch 54/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0960 - acc: 0.9640 - val_loss: 0.5800 - val_acc: 0.8490\n",
      "Epoch 55/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.0940 - acc: 0.9635 - val_loss: 0.5935 - val_acc: 0.8489\n",
      "Epoch 56/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0920 - acc: 0.9650 - val_loss: 0.5740 - val_acc: 0.8513\n",
      "Epoch 57/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0900 - acc: 0.9653 - val_loss: 0.5624 - val_acc: 0.8518\n",
      "Epoch 58/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0881 - acc: 0.9658 - val_loss: 0.5894 - val_acc: 0.8478\n",
      "Epoch 59/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0882 - acc: 0.9655 - val_loss: 0.5436 - val_acc: 0.8566\n",
      "Epoch 60/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0849 - acc: 0.9669 - val_loss: 0.5759 - val_acc: 0.8510\n",
      "Epoch 61/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0852 - acc: 0.9664 - val_loss: 0.5653 - val_acc: 0.8557\n",
      "Epoch 62/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.0863 - acc: 0.9664 - val_loss: 0.5736 - val_acc: 0.8555\n",
      "Epoch 63/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0818 - acc: 0.9688 - val_loss: 0.5722 - val_acc: 0.8550\n",
      "Epoch 64/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0783 - acc: 0.9690 - val_loss: 0.5893 - val_acc: 0.8572\n",
      "Epoch 65/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0804 - acc: 0.9690 - val_loss: 0.5849 - val_acc: 0.8596\n",
      "Epoch 66/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0809 - acc: 0.9684 - val_loss: 0.5681 - val_acc: 0.8614\n",
      "Epoch 67/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.0764 - acc: 0.9705 - val_loss: 0.5897 - val_acc: 0.8555\n",
      "Epoch 68/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0744 - acc: 0.9716 - val_loss: 0.6001 - val_acc: 0.8520\n",
      "Epoch 69/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0757 - acc: 0.9706 - val_loss: 0.5935 - val_acc: 0.8592\n",
      "Epoch 70/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0746 - acc: 0.9705 - val_loss: 0.5607 - val_acc: 0.8647\n",
      "Epoch 71/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0731 - acc: 0.9710 - val_loss: 0.5961 - val_acc: 0.8586\n",
      "Epoch 72/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0719 - acc: 0.9727 - val_loss: 0.5945 - val_acc: 0.8566\n",
      "Epoch 73/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0722 - acc: 0.9722 - val_loss: 0.5708 - val_acc: 0.8600\n",
      "Epoch 74/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0691 - acc: 0.9732 - val_loss: 0.6004 - val_acc: 0.8633\n",
      "Epoch 75/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0696 - acc: 0.9737 - val_loss: 0.5961 - val_acc: 0.8580\n",
      "Epoch 76/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0695 - acc: 0.9733 - val_loss: 0.5795 - val_acc: 0.8609\n",
      "Epoch 77/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0675 - acc: 0.9731 - val_loss: 0.5969 - val_acc: 0.8598\n",
      "Epoch 78/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0673 - acc: 0.9743 - val_loss: 0.6007 - val_acc: 0.8592\n",
      "Epoch 79/400\n",
      "40350/40350 [==============================] - 16s 394us/sample - loss: 0.0669 - acc: 0.9736 - val_loss: 0.5991 - val_acc: 0.8574\n",
      "Epoch 80/400\n",
      "40350/40350 [==============================] - 16s 398us/sample - loss: 0.0664 - acc: 0.9743 - val_loss: 0.5812 - val_acc: 0.8628\n",
      "Epoch 81/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.0632 - acc: 0.9760 - val_loss: 0.5974 - val_acc: 0.8581\n",
      "Epoch 82/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0632 - acc: 0.9755 - val_loss: 0.5983 - val_acc: 0.8592\n",
      "Epoch 83/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0639 - acc: 0.9753 - val_loss: 0.6083 - val_acc: 0.8549\n",
      "Epoch 84/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0602 - acc: 0.9765 - val_loss: 0.6126 - val_acc: 0.8591\n",
      "Epoch 85/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0606 - acc: 0.9765 - val_loss: 0.6181 - val_acc: 0.8562\n",
      "Epoch 86/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0622 - acc: 0.9757 - val_loss: 0.5798 - val_acc: 0.8633\n",
      "Epoch 87/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0614 - acc: 0.9761 - val_loss: 0.5949 - val_acc: 0.8631\n",
      "Epoch 88/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0581 - acc: 0.9779 - val_loss: 0.6411 - val_acc: 0.8607\n",
      "Epoch 89/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0587 - acc: 0.9766 - val_loss: 0.6449 - val_acc: 0.8604\n",
      "Epoch 90/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0613 - acc: 0.9761 - val_loss: 0.6074 - val_acc: 0.8657\n",
      "Epoch 91/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0558 - acc: 0.9779 - val_loss: 0.6303 - val_acc: 0.8668\n",
      "Epoch 92/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0598 - acc: 0.9772 - val_loss: 0.5955 - val_acc: 0.8675\n",
      "Epoch 93/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0599 - acc: 0.9770 - val_loss: 0.6117 - val_acc: 0.8632\n",
      "Epoch 94/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0547 - acc: 0.9785 - val_loss: 0.6211 - val_acc: 0.8635\n",
      "Epoch 95/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0559 - acc: 0.9781 - val_loss: 0.6481 - val_acc: 0.8597\n",
      "Epoch 96/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0552 - acc: 0.9791 - val_loss: 0.6307 - val_acc: 0.8630\n",
      "Epoch 97/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0537 - acc: 0.9788 - val_loss: 0.6344 - val_acc: 0.8619\n",
      "Epoch 98/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0518 - acc: 0.9798 - val_loss: 0.6141 - val_acc: 0.8613\n",
      "Epoch 99/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0545 - acc: 0.9787 - val_loss: 0.6164 - val_acc: 0.8621\n",
      "Epoch 100/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0548 - acc: 0.9790 - val_loss: 0.6384 - val_acc: 0.8618\n",
      "Epoch 101/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0559 - acc: 0.9783 - val_loss: 0.6031 - val_acc: 0.8605\n",
      "Epoch 102/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0538 - acc: 0.9787 - val_loss: 0.6008 - val_acc: 0.8648\n",
      "Epoch 103/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0529 - acc: 0.9801 - val_loss: 0.6178 - val_acc: 0.8610\n",
      "Epoch 104/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0501 - acc: 0.9805 - val_loss: 0.6272 - val_acc: 0.8603\n",
      "Epoch 105/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0490 - acc: 0.9809 - val_loss: 0.6044 - val_acc: 0.8642\n",
      "Epoch 106/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0462 - acc: 0.9817 - val_loss: 0.6402 - val_acc: 0.8602\n",
      "Epoch 107/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0482 - acc: 0.9813 - val_loss: 0.6289 - val_acc: 0.8687\n",
      "Epoch 108/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0476 - acc: 0.9812 - val_loss: 0.6412 - val_acc: 0.8600\n",
      "Epoch 109/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0475 - acc: 0.9817 - val_loss: 0.6292 - val_acc: 0.8627\n",
      "Epoch 110/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0485 - acc: 0.9811 - val_loss: 0.6325 - val_acc: 0.8627\n",
      "Epoch 111/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0490 - acc: 0.9813 - val_loss: 0.6340 - val_acc: 0.8575\n",
      "Epoch 112/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0472 - acc: 0.9819 - val_loss: 0.6335 - val_acc: 0.8632\n",
      "Epoch 113/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0466 - acc: 0.9819 - val_loss: 0.6133 - val_acc: 0.8657\n",
      "Epoch 114/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0448 - acc: 0.9829 - val_loss: 0.6132 - val_acc: 0.8701\n",
      "Epoch 115/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0447 - acc: 0.9828 - val_loss: 0.6166 - val_acc: 0.8686\n",
      "Epoch 116/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0430 - acc: 0.9831 - val_loss: 0.6303 - val_acc: 0.8671\n",
      "Epoch 117/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0446 - acc: 0.9827 - val_loss: 0.6151 - val_acc: 0.8669\n",
      "Epoch 118/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0440 - acc: 0.9833 - val_loss: 0.6352 - val_acc: 0.8626\n",
      "Epoch 119/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0423 - acc: 0.9834 - val_loss: 0.6350 - val_acc: 0.8677\n",
      "Epoch 120/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0436 - acc: 0.9827 - val_loss: 0.6439 - val_acc: 0.8667\n",
      "Epoch 121/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0435 - acc: 0.9833 - val_loss: 0.6276 - val_acc: 0.8667\n",
      "Epoch 122/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0419 - acc: 0.9837 - val_loss: 0.6573 - val_acc: 0.8598\n",
      "Epoch 123/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0424 - acc: 0.9838 - val_loss: 0.6357 - val_acc: 0.8652\n",
      "Epoch 124/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0421 - acc: 0.9831 - val_loss: 0.6638 - val_acc: 0.8637\n",
      "Epoch 125/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0407 - acc: 0.9842 - val_loss: 0.6530 - val_acc: 0.8663\n",
      "Epoch 126/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0419 - acc: 0.9842 - val_loss: 0.6556 - val_acc: 0.8675\n",
      "Epoch 127/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0432 - acc: 0.9833 - val_loss: 0.6366 - val_acc: 0.8672\n",
      "Epoch 128/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0402 - acc: 0.9844 - val_loss: 0.6286 - val_acc: 0.8697\n",
      "Epoch 129/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0432 - acc: 0.9831 - val_loss: 0.6647 - val_acc: 0.8680\n",
      "Epoch 130/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0419 - acc: 0.9841 - val_loss: 0.6327 - val_acc: 0.8700\n",
      "Epoch 131/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0368 - acc: 0.9861 - val_loss: 0.6431 - val_acc: 0.8734\n",
      "Epoch 132/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0392 - acc: 0.9853 - val_loss: 0.6585 - val_acc: 0.8684\n",
      "Epoch 133/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0382 - acc: 0.9858 - val_loss: 0.6734 - val_acc: 0.8641\n",
      "Epoch 134/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0375 - acc: 0.9856 - val_loss: 0.6518 - val_acc: 0.8659\n",
      "Epoch 135/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0378 - acc: 0.9852 - val_loss: 0.6504 - val_acc: 0.8700\n",
      "Epoch 136/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0376 - acc: 0.9851 - val_loss: 0.6418 - val_acc: 0.8699\n",
      "Epoch 137/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0376 - acc: 0.9856 - val_loss: 0.6622 - val_acc: 0.8720\n",
      "Epoch 138/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0376 - acc: 0.9853 - val_loss: 0.6467 - val_acc: 0.8691\n",
      "Epoch 139/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0367 - acc: 0.9862 - val_loss: 0.6568 - val_acc: 0.8679\n",
      "Epoch 140/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0370 - acc: 0.9863 - val_loss: 0.6531 - val_acc: 0.8669\n",
      "Epoch 141/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0364 - acc: 0.9862 - val_loss: 0.6642 - val_acc: 0.8701\n",
      "Epoch 142/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0368 - acc: 0.9858 - val_loss: 0.6612 - val_acc: 0.8704\n",
      "Epoch 143/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0344 - acc: 0.9866 - val_loss: 0.6469 - val_acc: 0.8692\n",
      "Epoch 144/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0351 - acc: 0.9871 - val_loss: 0.6762 - val_acc: 0.8688\n",
      "Epoch 145/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0346 - acc: 0.9870 - val_loss: 0.6563 - val_acc: 0.8730\n",
      "Epoch 146/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0344 - acc: 0.9868 - val_loss: 0.6566 - val_acc: 0.8748\n",
      "Epoch 147/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0327 - acc: 0.9867 - val_loss: 0.6578 - val_acc: 0.8718\n",
      "Epoch 148/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0354 - acc: 0.9871 - val_loss: 0.6725 - val_acc: 0.8687\n",
      "Epoch 149/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0344 - acc: 0.9867 - val_loss: 0.6822 - val_acc: 0.8683\n",
      "Epoch 150/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0338 - acc: 0.9878 - val_loss: 0.6565 - val_acc: 0.8713\n",
      "Epoch 151/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0332 - acc: 0.9872 - val_loss: 0.6481 - val_acc: 0.8750\n",
      "Epoch 152/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0338 - acc: 0.9875 - val_loss: 0.6451 - val_acc: 0.8741\n",
      "Epoch 153/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0332 - acc: 0.9877 - val_loss: 0.6778 - val_acc: 0.8714\n",
      "Epoch 154/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0336 - acc: 0.9879 - val_loss: 0.6871 - val_acc: 0.8704\n",
      "Epoch 155/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0308 - acc: 0.9881 - val_loss: 0.6908 - val_acc: 0.8712\n",
      "Epoch 156/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0324 - acc: 0.9884 - val_loss: 0.6930 - val_acc: 0.8704\n",
      "Epoch 157/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0316 - acc: 0.9881 - val_loss: 0.6991 - val_acc: 0.8668\n",
      "Epoch 158/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0299 - acc: 0.9891 - val_loss: 0.7103 - val_acc: 0.8672\n",
      "Epoch 159/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0323 - acc: 0.9880 - val_loss: 0.6747 - val_acc: 0.8715\n",
      "Epoch 160/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0284 - acc: 0.9899 - val_loss: 0.7107 - val_acc: 0.8697\n",
      "Epoch 161/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0301 - acc: 0.9889 - val_loss: 0.6856 - val_acc: 0.8746\n",
      "Epoch 162/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0324 - acc: 0.9884 - val_loss: 0.6847 - val_acc: 0.8686\n",
      "Epoch 163/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0302 - acc: 0.9894 - val_loss: 0.6927 - val_acc: 0.8708\n",
      "Epoch 164/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0294 - acc: 0.9888 - val_loss: 0.7077 - val_acc: 0.8677\n",
      "Epoch 165/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0287 - acc: 0.9892 - val_loss: 0.7082 - val_acc: 0.8693\n",
      "Epoch 166/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0286 - acc: 0.9893 - val_loss: 0.6604 - val_acc: 0.8758\n",
      "Epoch 167/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0295 - acc: 0.9888 - val_loss: 0.6921 - val_acc: 0.8699\n",
      "Epoch 168/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0301 - acc: 0.9891 - val_loss: 0.6991 - val_acc: 0.8723\n",
      "Epoch 169/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0289 - acc: 0.9895 - val_loss: 0.7077 - val_acc: 0.8706\n",
      "Epoch 170/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0280 - acc: 0.9903 - val_loss: 0.6800 - val_acc: 0.8712\n",
      "Epoch 171/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0260 - acc: 0.9905 - val_loss: 0.7029 - val_acc: 0.8703\n",
      "Epoch 172/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0272 - acc: 0.9901 - val_loss: 0.6896 - val_acc: 0.8675\n",
      "Epoch 173/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0259 - acc: 0.9907 - val_loss: 0.6880 - val_acc: 0.8708\n",
      "Epoch 174/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0287 - acc: 0.9897 - val_loss: 0.6912 - val_acc: 0.8657\n",
      "Epoch 175/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0274 - acc: 0.9902 - val_loss: 0.6827 - val_acc: 0.8654\n",
      "Epoch 176/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0282 - acc: 0.9899 - val_loss: 0.6969 - val_acc: 0.8692\n",
      "Epoch 177/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0256 - acc: 0.9910 - val_loss: 0.7223 - val_acc: 0.8670\n",
      "Epoch 178/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0269 - acc: 0.9908 - val_loss: 0.6872 - val_acc: 0.8721\n",
      "Epoch 179/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0265 - acc: 0.9905 - val_loss: 0.6620 - val_acc: 0.8779\n",
      "Epoch 180/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0260 - acc: 0.9904 - val_loss: 0.6890 - val_acc: 0.8725\n",
      "Epoch 181/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0253 - acc: 0.9912 - val_loss: 0.6744 - val_acc: 0.8758\n",
      "Epoch 182/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0250 - acc: 0.9911 - val_loss: 0.6819 - val_acc: 0.8718\n",
      "Epoch 183/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0242 - acc: 0.9912 - val_loss: 0.6854 - val_acc: 0.8777\n",
      "Epoch 184/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0271 - acc: 0.9904 - val_loss: 0.6817 - val_acc: 0.8772\n",
      "Epoch 185/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0246 - acc: 0.9911 - val_loss: 0.7014 - val_acc: 0.8719\n",
      "Epoch 186/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0252 - acc: 0.9913 - val_loss: 0.6873 - val_acc: 0.8759\n",
      "Epoch 187/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0253 - acc: 0.9912 - val_loss: 0.6570 - val_acc: 0.8813\n",
      "Epoch 188/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0241 - acc: 0.9912 - val_loss: 0.6784 - val_acc: 0.8760\n",
      "Epoch 189/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0237 - acc: 0.9919 - val_loss: 0.6816 - val_acc: 0.8759\n",
      "Epoch 190/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0250 - acc: 0.9913 - val_loss: 0.6856 - val_acc: 0.8728\n",
      "Epoch 191/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0241 - acc: 0.9915 - val_loss: 0.7045 - val_acc: 0.8685\n",
      "Epoch 192/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0245 - acc: 0.9912 - val_loss: 0.6789 - val_acc: 0.8688\n",
      "Epoch 193/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0235 - acc: 0.9920 - val_loss: 0.6811 - val_acc: 0.8735\n",
      "Epoch 194/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0225 - acc: 0.9924 - val_loss: 0.6714 - val_acc: 0.8758\n",
      "Epoch 195/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0223 - acc: 0.9917 - val_loss: 0.6756 - val_acc: 0.8721\n",
      "Epoch 196/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0236 - acc: 0.9918 - val_loss: 0.7024 - val_acc: 0.8702\n",
      "Epoch 197/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0228 - acc: 0.9920 - val_loss: 0.6898 - val_acc: 0.8699\n",
      "Epoch 198/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0233 - acc: 0.9917 - val_loss: 0.6709 - val_acc: 0.8706\n",
      "Epoch 199/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0242 - acc: 0.9916 - val_loss: 0.6785 - val_acc: 0.8761\n",
      "Epoch 200/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0224 - acc: 0.9929 - val_loss: 0.6777 - val_acc: 0.8732\n",
      "Epoch 201/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0220 - acc: 0.9927 - val_loss: 0.7031 - val_acc: 0.8748\n",
      "Epoch 202/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0234 - acc: 0.9917 - val_loss: 0.6956 - val_acc: 0.8709\n",
      "Epoch 203/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0228 - acc: 0.9920 - val_loss: 0.6933 - val_acc: 0.8726\n",
      "Epoch 204/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0217 - acc: 0.9926 - val_loss: 0.6809 - val_acc: 0.8732\n",
      "Epoch 205/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0215 - acc: 0.9924 - val_loss: 0.7040 - val_acc: 0.8725\n",
      "Epoch 206/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0210 - acc: 0.9925 - val_loss: 0.7095 - val_acc: 0.8731\n",
      "Epoch 207/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0204 - acc: 0.9930 - val_loss: 0.6891 - val_acc: 0.8725\n",
      "Epoch 208/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0220 - acc: 0.9920 - val_loss: 0.6768 - val_acc: 0.8781\n",
      "Epoch 209/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0199 - acc: 0.9928 - val_loss: 0.6982 - val_acc: 0.8785\n",
      "Epoch 210/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0192 - acc: 0.9930 - val_loss: 0.7337 - val_acc: 0.8732\n",
      "Epoch 211/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0217 - acc: 0.9932 - val_loss: 0.7054 - val_acc: 0.8699\n",
      "Epoch 212/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0212 - acc: 0.9923 - val_loss: 0.7220 - val_acc: 0.8749\n",
      "Epoch 213/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0204 - acc: 0.9929 - val_loss: 0.6818 - val_acc: 0.8801\n",
      "Epoch 214/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0214 - acc: 0.9930 - val_loss: 0.6980 - val_acc: 0.8759\n",
      "Epoch 215/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0197 - acc: 0.9932 - val_loss: 0.6986 - val_acc: 0.8750\n",
      "Epoch 216/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0176 - acc: 0.9940 - val_loss: 0.7231 - val_acc: 0.8760\n",
      "Epoch 217/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0192 - acc: 0.9929 - val_loss: 0.7243 - val_acc: 0.8747\n",
      "Epoch 218/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0182 - acc: 0.9938 - val_loss: 0.7289 - val_acc: 0.8750\n",
      "Epoch 219/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0186 - acc: 0.9936 - val_loss: 0.6846 - val_acc: 0.8781\n",
      "Epoch 220/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0179 - acc: 0.9940 - val_loss: 0.7010 - val_acc: 0.8798\n",
      "Epoch 221/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0185 - acc: 0.9939 - val_loss: 0.6897 - val_acc: 0.8775\n",
      "Epoch 222/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0181 - acc: 0.9939 - val_loss: 0.7241 - val_acc: 0.8752\n",
      "Epoch 223/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0185 - acc: 0.9930 - val_loss: 0.7213 - val_acc: 0.8741\n",
      "Epoch 224/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0203 - acc: 0.9929 - val_loss: 0.7243 - val_acc: 0.8734\n",
      "Epoch 225/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0216 - acc: 0.9928 - val_loss: 0.7274 - val_acc: 0.8708\n",
      "Epoch 226/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0183 - acc: 0.9936 - val_loss: 0.7499 - val_acc: 0.8703\n",
      "Epoch 227/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0201 - acc: 0.9931 - val_loss: 0.7513 - val_acc: 0.8713\n",
      "Epoch 228/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0179 - acc: 0.9939 - val_loss: 0.7316 - val_acc: 0.8687\n",
      "Epoch 229/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0196 - acc: 0.9932 - val_loss: 0.7425 - val_acc: 0.8685\n",
      "Epoch 230/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0169 - acc: 0.9944 - val_loss: 0.7362 - val_acc: 0.8703\n",
      "Epoch 231/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0178 - acc: 0.9945 - val_loss: 0.7221 - val_acc: 0.8732\n",
      "Epoch 232/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0177 - acc: 0.9940 - val_loss: 0.7268 - val_acc: 0.8726\n",
      "Epoch 233/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0172 - acc: 0.9942 - val_loss: 0.7389 - val_acc: 0.8737\n",
      "Epoch 234/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0174 - acc: 0.9940 - val_loss: 0.6966 - val_acc: 0.8747\n",
      "Epoch 235/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0180 - acc: 0.9942 - val_loss: 0.7102 - val_acc: 0.8758\n",
      "Epoch 236/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0199 - acc: 0.9935 - val_loss: 0.7164 - val_acc: 0.8724\n",
      "Epoch 237/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0195 - acc: 0.9935 - val_loss: 0.7179 - val_acc: 0.8745\n",
      "Epoch 238/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0173 - acc: 0.9944 - val_loss: 0.6943 - val_acc: 0.8785\n",
      "Epoch 239/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0177 - acc: 0.9940 - val_loss: 0.7255 - val_acc: 0.8744\n",
      "Epoch 240/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0164 - acc: 0.9943 - val_loss: 0.7251 - val_acc: 0.8773\n",
      "Epoch 241/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0160 - acc: 0.9948 - val_loss: 0.7429 - val_acc: 0.8793\n",
      "Epoch 242/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0162 - acc: 0.9944 - val_loss: 0.7145 - val_acc: 0.8804\n",
      "Epoch 243/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0167 - acc: 0.9947 - val_loss: 0.7319 - val_acc: 0.8775\n",
      "Epoch 244/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0167 - acc: 0.9942 - val_loss: 0.7355 - val_acc: 0.8811\n",
      "Epoch 245/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0171 - acc: 0.9941 - val_loss: 0.7006 - val_acc: 0.8783\n",
      "Epoch 246/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0172 - acc: 0.9942 - val_loss: 0.7086 - val_acc: 0.8749\n",
      "Epoch 247/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0166 - acc: 0.9943 - val_loss: 0.7063 - val_acc: 0.8764\n",
      "Epoch 248/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0177 - acc: 0.9942 - val_loss: 0.7038 - val_acc: 0.8775\n",
      "Epoch 249/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0169 - acc: 0.9948 - val_loss: 0.7498 - val_acc: 0.8734\n",
      "Epoch 250/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0158 - acc: 0.9947 - val_loss: 0.7305 - val_acc: 0.8759\n",
      "Epoch 251/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0150 - acc: 0.9947 - val_loss: 0.7377 - val_acc: 0.8772\n",
      "Epoch 252/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0161 - acc: 0.9947 - val_loss: 0.7069 - val_acc: 0.8813\n",
      "Epoch 253/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0160 - acc: 0.9949 - val_loss: 0.7448 - val_acc: 0.8772\n",
      "Epoch 254/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0144 - acc: 0.9950 - val_loss: 0.7083 - val_acc: 0.8803\n",
      "Epoch 255/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0148 - acc: 0.9949 - val_loss: 0.7234 - val_acc: 0.8773\n",
      "Epoch 256/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0147 - acc: 0.9951 - val_loss: 0.7098 - val_acc: 0.8803\n",
      "Epoch 257/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0141 - acc: 0.9953 - val_loss: 0.7393 - val_acc: 0.8782\n",
      "Epoch 258/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0156 - acc: 0.9952 - val_loss: 0.7459 - val_acc: 0.8773\n",
      "Epoch 259/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0160 - acc: 0.9946 - val_loss: 0.6926 - val_acc: 0.8795\n",
      "Epoch 260/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0142 - acc: 0.9950 - val_loss: 0.7287 - val_acc: 0.8771\n",
      "Epoch 261/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0159 - acc: 0.9944 - val_loss: 0.7135 - val_acc: 0.8750\n",
      "Epoch 262/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0141 - acc: 0.9954 - val_loss: 0.7104 - val_acc: 0.8773\n",
      "Epoch 263/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0165 - acc: 0.9949 - val_loss: 0.7137 - val_acc: 0.8792\n",
      "Epoch 264/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0151 - acc: 0.9951 - val_loss: 0.6955 - val_acc: 0.8832\n",
      "Epoch 265/400\n",
      "40350/40350 [==============================] - 16s 386us/sample - loss: 0.0168 - acc: 0.9945 - val_loss: 0.6995 - val_acc: 0.8819\n",
      "Epoch 266/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0139 - acc: 0.9955 - val_loss: 0.7366 - val_acc: 0.8789\n",
      "Epoch 267/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0141 - acc: 0.9952 - val_loss: 0.7576 - val_acc: 0.8795\n",
      "Epoch 268/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0160 - acc: 0.9947 - val_loss: 0.7168 - val_acc: 0.8805\n",
      "Epoch 269/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0151 - acc: 0.9952 - val_loss: 0.7376 - val_acc: 0.8801\n",
      "Epoch 270/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0149 - acc: 0.9949 - val_loss: 0.7207 - val_acc: 0.8784\n",
      "Epoch 271/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0145 - acc: 0.9952 - val_loss: 0.7357 - val_acc: 0.8773\n",
      "Epoch 272/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0157 - acc: 0.9948 - val_loss: 0.7347 - val_acc: 0.8801\n",
      "Epoch 273/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0146 - acc: 0.9953 - val_loss: 0.7508 - val_acc: 0.8798\n",
      "Epoch 274/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0142 - acc: 0.9954 - val_loss: 0.7530 - val_acc: 0.8764\n",
      "Epoch 275/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0154 - acc: 0.9950 - val_loss: 0.7174 - val_acc: 0.8816\n",
      "Epoch 276/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0148 - acc: 0.9946 - val_loss: 0.7235 - val_acc: 0.8797\n",
      "Epoch 277/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0149 - acc: 0.9951 - val_loss: 0.7349 - val_acc: 0.8793\n",
      "Epoch 278/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0148 - acc: 0.9953 - val_loss: 0.7249 - val_acc: 0.8803\n",
      "Epoch 279/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0152 - acc: 0.9951 - val_loss: 0.6966 - val_acc: 0.8809\n",
      "Epoch 280/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0159 - acc: 0.9949 - val_loss: 0.7399 - val_acc: 0.8798\n",
      "Epoch 281/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0141 - acc: 0.9957 - val_loss: 0.7014 - val_acc: 0.8797\n",
      "Epoch 282/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0144 - acc: 0.9952 - val_loss: 0.7247 - val_acc: 0.8779\n",
      "Epoch 283/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0153 - acc: 0.9947 - val_loss: 0.7340 - val_acc: 0.8765\n",
      "Epoch 284/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0146 - acc: 0.9951 - val_loss: 0.7297 - val_acc: 0.8794\n",
      "Epoch 285/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0160 - acc: 0.9945 - val_loss: 0.7193 - val_acc: 0.8802\n",
      "Epoch 286/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0131 - acc: 0.9954 - val_loss: 0.7358 - val_acc: 0.8809\n",
      "Epoch 287/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0145 - acc: 0.9953 - val_loss: 0.7345 - val_acc: 0.8791\n",
      "Epoch 288/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0139 - acc: 0.9954 - val_loss: 0.7413 - val_acc: 0.8776\n",
      "Epoch 289/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0138 - acc: 0.9954 - val_loss: 0.7710 - val_acc: 0.8777\n",
      "Epoch 290/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0130 - acc: 0.9954 - val_loss: 0.7735 - val_acc: 0.8778\n",
      "Epoch 291/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0142 - acc: 0.9953 - val_loss: 0.7358 - val_acc: 0.8750\n",
      "Epoch 292/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0125 - acc: 0.9955 - val_loss: 0.7439 - val_acc: 0.8793\n",
      "Epoch 293/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0137 - acc: 0.9954 - val_loss: 0.7587 - val_acc: 0.8777\n",
      "Epoch 294/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0129 - acc: 0.9958 - val_loss: 0.7594 - val_acc: 0.8759\n",
      "Epoch 295/400\n",
      "40350/40350 [==============================] - 16s 387us/sample - loss: 0.0124 - acc: 0.9958 - val_loss: 0.7696 - val_acc: 0.8766\n",
      "Epoch 296/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0139 - acc: 0.9955 - val_loss: 0.7288 - val_acc: 0.8802\n",
      "Epoch 297/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0141 - acc: 0.9955 - val_loss: 0.7519 - val_acc: 0.8780\n",
      "Epoch 298/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0145 - acc: 0.9952 - val_loss: 0.7044 - val_acc: 0.8811\n",
      "Epoch 299/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0143 - acc: 0.9954 - val_loss: 0.6904 - val_acc: 0.8803\n",
      "Epoch 300/400\n",
      "40350/40350 [==============================] - 16s 387us/sample - loss: 0.0164 - acc: 0.9951 - val_loss: 0.7195 - val_acc: 0.8800\n",
      "Epoch 301/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0120 - acc: 0.9961 - val_loss: 0.7090 - val_acc: 0.8821\n",
      "Epoch 302/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0146 - acc: 0.9953 - val_loss: 0.7107 - val_acc: 0.8827\n",
      "Epoch 303/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0149 - acc: 0.9955 - val_loss: 0.7183 - val_acc: 0.8779\n",
      "Epoch 304/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0130 - acc: 0.9959 - val_loss: 0.7241 - val_acc: 0.8766\n",
      "Epoch 305/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0147 - acc: 0.9953 - val_loss: 0.7417 - val_acc: 0.8760\n",
      "Epoch 306/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0150 - acc: 0.9954 - val_loss: 0.7164 - val_acc: 0.8822\n",
      "Epoch 307/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0137 - acc: 0.9957 - val_loss: 0.7123 - val_acc: 0.8869\n",
      "Epoch 308/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0124 - acc: 0.9962 - val_loss: 0.7190 - val_acc: 0.8837\n",
      "Epoch 309/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0144 - acc: 0.9952 - val_loss: 0.7543 - val_acc: 0.8794\n",
      "Epoch 310/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0139 - acc: 0.9957 - val_loss: 0.7005 - val_acc: 0.8853\n",
      "Epoch 311/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0144 - acc: 0.9954 - val_loss: 0.6975 - val_acc: 0.8837\n",
      "Epoch 312/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0140 - acc: 0.9953 - val_loss: 0.7199 - val_acc: 0.8815\n",
      "Epoch 313/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0133 - acc: 0.9956 - val_loss: 0.7253 - val_acc: 0.8821\n",
      "Epoch 314/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0134 - acc: 0.9959 - val_loss: 0.7066 - val_acc: 0.8877\n",
      "Epoch 315/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0159 - acc: 0.9950 - val_loss: 0.7169 - val_acc: 0.8813\n",
      "Epoch 316/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0128 - acc: 0.9958 - val_loss: 0.7164 - val_acc: 0.8846\n",
      "Epoch 317/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0132 - acc: 0.9957 - val_loss: 0.7069 - val_acc: 0.8844\n",
      "Epoch 318/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0137 - acc: 0.9953 - val_loss: 0.6849 - val_acc: 0.8853\n",
      "Epoch 319/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0120 - acc: 0.9959 - val_loss: 0.7202 - val_acc: 0.8865\n",
      "Epoch 320/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0121 - acc: 0.9962 - val_loss: 0.7232 - val_acc: 0.8826\n",
      "Epoch 321/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0119 - acc: 0.9959 - val_loss: 0.7149 - val_acc: 0.8845\n",
      "Epoch 322/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.6986 - val_acc: 0.8806\n",
      "Epoch 323/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0127 - acc: 0.9958 - val_loss: 0.7033 - val_acc: 0.8834\n",
      "Epoch 324/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0125 - acc: 0.9960 - val_loss: 0.7025 - val_acc: 0.8818\n",
      "Epoch 325/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0130 - acc: 0.9960 - val_loss: 0.6996 - val_acc: 0.8832\n",
      "Epoch 326/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0123 - acc: 0.9958 - val_loss: 0.7210 - val_acc: 0.8820\n",
      "Epoch 327/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0122 - acc: 0.9959 - val_loss: 0.6983 - val_acc: 0.8854\n",
      "Epoch 328/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0124 - acc: 0.9961 - val_loss: 0.7045 - val_acc: 0.8829\n",
      "Epoch 329/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0116 - acc: 0.9963 - val_loss: 0.7314 - val_acc: 0.8815\n",
      "Epoch 330/400\n",
      "40350/40350 [==============================] - 16s 388us/sample - loss: 0.0133 - acc: 0.9956 - val_loss: 0.7450 - val_acc: 0.8817\n",
      "Epoch 331/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0129 - acc: 0.9959 - val_loss: 0.7256 - val_acc: 0.8807\n",
      "Epoch 332/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0112 - acc: 0.9962 - val_loss: 0.7182 - val_acc: 0.8822\n",
      "Epoch 333/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0120 - acc: 0.9958 - val_loss: 0.7320 - val_acc: 0.8808\n",
      "Epoch 334/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0116 - acc: 0.9960 - val_loss: 0.7297 - val_acc: 0.8839\n",
      "Epoch 335/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0110 - acc: 0.9966 - val_loss: 0.7168 - val_acc: 0.8859\n",
      "Epoch 336/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0100 - acc: 0.9969 - val_loss: 0.7475 - val_acc: 0.8834\n",
      "Epoch 337/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0122 - acc: 0.9958 - val_loss: 0.7496 - val_acc: 0.8842\n",
      "Epoch 338/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0108 - acc: 0.9965 - val_loss: 0.7376 - val_acc: 0.8850\n",
      "Epoch 339/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0102 - acc: 0.9964 - val_loss: 0.7261 - val_acc: 0.8865\n",
      "Epoch 340/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0117 - acc: 0.9965 - val_loss: 0.7066 - val_acc: 0.8872\n",
      "Epoch 341/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0124 - acc: 0.9959 - val_loss: 0.7171 - val_acc: 0.8873\n",
      "Epoch 342/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0117 - acc: 0.9956 - val_loss: 0.7262 - val_acc: 0.8873\n",
      "Epoch 343/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0118 - acc: 0.9961 - val_loss: 0.7160 - val_acc: 0.8871\n",
      "Epoch 344/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0117 - acc: 0.9962 - val_loss: 0.7491 - val_acc: 0.8832\n",
      "Epoch 345/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0119 - acc: 0.9965 - val_loss: 0.7456 - val_acc: 0.8826\n",
      "Epoch 346/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0127 - acc: 0.9962 - val_loss: 0.7168 - val_acc: 0.8827\n",
      "Epoch 347/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0110 - acc: 0.9962 - val_loss: 0.7100 - val_acc: 0.8843\n",
      "Epoch 348/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0114 - acc: 0.9965 - val_loss: 0.7318 - val_acc: 0.8845\n",
      "Epoch 349/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0109 - acc: 0.9966 - val_loss: 0.7061 - val_acc: 0.8895\n",
      "Epoch 350/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0124 - acc: 0.9963 - val_loss: 0.6984 - val_acc: 0.8898\n",
      "Epoch 351/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0100 - acc: 0.9966 - val_loss: 0.7153 - val_acc: 0.8839\n",
      "Epoch 352/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0126 - acc: 0.9956 - val_loss: 0.7046 - val_acc: 0.8845\n",
      "Epoch 353/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.0117 - acc: 0.9964 - val_loss: 0.7017 - val_acc: 0.8872\n",
      "Epoch 354/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0125 - acc: 0.9961 - val_loss: 0.6972 - val_acc: 0.8879\n",
      "Epoch 355/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0123 - acc: 0.9961 - val_loss: 0.7256 - val_acc: 0.8844\n",
      "Epoch 356/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0127 - acc: 0.9959 - val_loss: 0.7405 - val_acc: 0.8815\n",
      "Epoch 357/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0121 - acc: 0.9962 - val_loss: 0.7116 - val_acc: 0.8835\n",
      "Epoch 358/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0113 - acc: 0.9963 - val_loss: 0.7088 - val_acc: 0.8879\n",
      "Epoch 359/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0118 - acc: 0.9961 - val_loss: 0.7299 - val_acc: 0.8822\n",
      "Epoch 360/400\n",
      "40350/40350 [==============================] - 16s 393us/sample - loss: 0.0130 - acc: 0.9962 - val_loss: 0.7069 - val_acc: 0.8837\n",
      "Epoch 361/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0119 - acc: 0.9961 - val_loss: 0.7228 - val_acc: 0.8824\n",
      "Epoch 362/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0129 - acc: 0.9959 - val_loss: 0.7103 - val_acc: 0.8846\n",
      "Epoch 363/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0112 - acc: 0.9963 - val_loss: 0.7038 - val_acc: 0.8843\n",
      "Epoch 364/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0105 - acc: 0.9967 - val_loss: 0.7291 - val_acc: 0.8816\n",
      "Epoch 365/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0100 - acc: 0.9965 - val_loss: 0.7109 - val_acc: 0.8837\n",
      "Epoch 366/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0122 - acc: 0.9959 - val_loss: 0.7026 - val_acc: 0.8832\n",
      "Epoch 367/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0115 - acc: 0.9963 - val_loss: 0.7108 - val_acc: 0.8837\n",
      "Epoch 368/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0112 - acc: 0.9959 - val_loss: 0.7014 - val_acc: 0.8828\n",
      "Epoch 369/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0111 - acc: 0.9967 - val_loss: 0.7218 - val_acc: 0.8867\n",
      "Epoch 370/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0104 - acc: 0.9965 - val_loss: 0.6925 - val_acc: 0.8845\n",
      "Epoch 371/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0101 - acc: 0.9969 - val_loss: 0.7116 - val_acc: 0.8853\n",
      "Epoch 372/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0109 - acc: 0.9968 - val_loss: 0.7060 - val_acc: 0.8858\n",
      "Epoch 373/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0106 - acc: 0.9970 - val_loss: 0.7086 - val_acc: 0.8838\n",
      "Epoch 374/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0117 - acc: 0.9960 - val_loss: 0.7225 - val_acc: 0.8821\n",
      "Epoch 375/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0122 - acc: 0.9959 - val_loss: 0.7299 - val_acc: 0.8814\n",
      "Epoch 376/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0130 - acc: 0.9961 - val_loss: 0.7277 - val_acc: 0.8860\n",
      "Epoch 377/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0106 - acc: 0.9965 - val_loss: 0.7129 - val_acc: 0.8806\n",
      "Epoch 378/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0102 - acc: 0.9964 - val_loss: 0.7279 - val_acc: 0.8844\n",
      "Epoch 379/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0119 - acc: 0.9962 - val_loss: 0.7211 - val_acc: 0.8818\n",
      "Epoch 380/400\n",
      "40350/40350 [==============================] - 16s 395us/sample - loss: 0.0102 - acc: 0.9965 - val_loss: 0.7147 - val_acc: 0.8805\n",
      "Epoch 381/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 0.7128 - val_acc: 0.8826\n",
      "Epoch 382/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.7249 - val_acc: 0.8817\n",
      "Epoch 383/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0105 - acc: 0.9965 - val_loss: 0.7334 - val_acc: 0.8828\n",
      "Epoch 384/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0116 - acc: 0.9962 - val_loss: 0.7254 - val_acc: 0.8859\n",
      "Epoch 385/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0107 - acc: 0.9965 - val_loss: 0.7175 - val_acc: 0.8860\n",
      "Epoch 386/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0127 - acc: 0.9961 - val_loss: 0.7432 - val_acc: 0.8834\n",
      "Epoch 387/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0097 - acc: 0.9969 - val_loss: 0.7111 - val_acc: 0.8858\n",
      "Epoch 388/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0115 - acc: 0.9962 - val_loss: 0.7137 - val_acc: 0.8851\n",
      "Epoch 389/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0111 - acc: 0.9959 - val_loss: 0.7526 - val_acc: 0.8804\n",
      "Epoch 390/400\n",
      "40350/40350 [==============================] - 16s 389us/sample - loss: 0.0118 - acc: 0.9960 - val_loss: 0.7460 - val_acc: 0.8815\n",
      "Epoch 391/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0115 - acc: 0.9961 - val_loss: 0.7327 - val_acc: 0.8811\n",
      "Epoch 392/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0111 - acc: 0.9964 - val_loss: 0.7285 - val_acc: 0.8856\n",
      "Epoch 393/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0109 - acc: 0.9967 - val_loss: 0.7271 - val_acc: 0.8866\n",
      "Epoch 394/400\n",
      "40350/40350 [==============================] - 16s 392us/sample - loss: 0.0080 - acc: 0.9973 - val_loss: 0.7647 - val_acc: 0.8801\n",
      "Epoch 395/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0115 - acc: 0.9964 - val_loss: 0.7137 - val_acc: 0.8846\n",
      "Epoch 396/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0101 - acc: 0.9967 - val_loss: 0.7433 - val_acc: 0.8824\n",
      "Epoch 397/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0097 - acc: 0.9969 - val_loss: 0.7446 - val_acc: 0.8851\n",
      "Epoch 398/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0103 - acc: 0.9967 - val_loss: 0.7284 - val_acc: 0.8851\n",
      "Epoch 399/400\n",
      "40350/40350 [==============================] - 16s 390us/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 0.7452 - val_acc: 0.8844\n",
      "Epoch 400/400\n",
      "40350/40350 [==============================] - 16s 391us/sample - loss: 0.0096 - acc: 0.9968 - val_loss: 0.7190 - val_acc: 0.8856\n"
     ]
    }
   ],
   "source": [
    "model = trainModel(builtCompositeModel(drop_out_rate=0.5),[train_headline, train_first_body, train_last_body],[hold_out_headline, hold_out_first_body, hold_out_last_body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 736,
     "status": "error",
     "timestamp": 1564065690325,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "PZyDbD8dznJO",
    "outputId": "1092bc70-dbca-4850-96f0-17beb19f52e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPOSITE\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb960419bccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COMPOSITE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhold_out_headline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhold_out_first_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhold_out_last_body\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhold_out_stanceFinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print('COMPOSITE')\n",
    "pred = model.predict([hold_out_headline, hold_out_first_body,hold_out_last_body])\n",
    "y_classes = pred.argmax(axis=-1)\n",
    "actual = hold_out_stanceFinal\n",
    "evaluate(y_classes, actual)\n",
    "\n",
    "pred = model.predict([competition_headline, competition_first_body,competition_last_body])\n",
    "y_classes = pred.argmax(axis=-1)\n",
    "actual = competition_stanceFinal\n",
    "evaluate(y_classes, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3012610,
     "status": "ok",
     "timestamp": 1563933428207,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "BjVDnGIyyy7S",
    "outputId": "6ae2434a-78d8-4b59-afdc-8066d72cb633"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0724 00:56:45.422139 140532354664320 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_body_input (InputLayer)   [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "headline_input (InputLayer)     [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "headline_word_embedding_layer ( multiple             8825700     headline_input[0][0]             \n",
      "                                                                 first_body_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer_encoder (LSTM)       [(None, 300), (None, 721200      headline_word_embedding_layer[0][\n",
      "__________________________________________________________________________________________________\n",
      "lstm_layer_first_body (LSTM)    [(None, 300), (None, 721200      headline_word_embedding_layer[1][\n",
      "                                                                 lstm_layer_encoder[0][1]         \n",
      "                                                                 lstm_layer_encoder[0][2]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_0 (Dropout)             (None, 300)          0           lstm_layer_first_body[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 4)            1204        dropout_0[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,269,304\n",
      "Trainable params: 1,443,604\n",
      "Non-trainable params: 8,825,700\n",
      "__________________________________________________________________________________________________\n",
      "Train on 40350 samples, validate on 9622 samples\n",
      "Epoch 1/400\n",
      "40350/40350 [==============================] - 11s 283us/sample - loss: 0.8313 - acc: 0.7214 - val_loss: 0.8246 - val_acc: 0.7169\n",
      "Epoch 2/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.7666 - acc: 0.7341 - val_loss: 0.8129 - val_acc: 0.7169\n",
      "Epoch 3/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.7370 - acc: 0.7393 - val_loss: 0.7693 - val_acc: 0.7282\n",
      "Epoch 4/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.7046 - acc: 0.7521 - val_loss: 0.7569 - val_acc: 0.7303\n",
      "Epoch 5/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.6738 - acc: 0.7636 - val_loss: 0.7305 - val_acc: 0.7390\n",
      "Epoch 6/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.6329 - acc: 0.7731 - val_loss: 0.7047 - val_acc: 0.7412\n",
      "Epoch 7/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.5926 - acc: 0.7837 - val_loss: 0.6783 - val_acc: 0.7411\n",
      "Epoch 8/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.5473 - acc: 0.7970 - val_loss: 0.6495 - val_acc: 0.7513\n",
      "Epoch 9/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.5083 - acc: 0.8076 - val_loss: 0.6539 - val_acc: 0.7307\n",
      "Epoch 10/400\n",
      "40350/40350 [==============================] - 11s 278us/sample - loss: 0.4751 - acc: 0.8184 - val_loss: 0.6141 - val_acc: 0.7501\n",
      "Epoch 11/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.4488 - acc: 0.8284 - val_loss: 0.6149 - val_acc: 0.7453\n",
      "Epoch 12/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.4207 - acc: 0.8373 - val_loss: 0.6079 - val_acc: 0.7483\n",
      "Epoch 13/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.4012 - acc: 0.8462 - val_loss: 0.5969 - val_acc: 0.7521\n",
      "Epoch 14/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.3850 - acc: 0.8529 - val_loss: 0.6004 - val_acc: 0.7769\n",
      "Epoch 15/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.3644 - acc: 0.8601 - val_loss: 0.6056 - val_acc: 0.7764\n",
      "Epoch 16/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.3498 - acc: 0.8680 - val_loss: 0.5672 - val_acc: 0.7901\n",
      "Epoch 17/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.3330 - acc: 0.8751 - val_loss: 0.5847 - val_acc: 0.7896\n",
      "Epoch 18/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.3156 - acc: 0.8814 - val_loss: 0.5655 - val_acc: 0.7918\n",
      "Epoch 19/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.3053 - acc: 0.8822 - val_loss: 0.5275 - val_acc: 0.8046\n",
      "Epoch 20/400\n",
      "40350/40350 [==============================] - 9s 227us/sample - loss: 0.2941 - acc: 0.8883 - val_loss: 0.5613 - val_acc: 0.7936\n",
      "Epoch 21/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.2817 - acc: 0.8930 - val_loss: 0.5480 - val_acc: 0.7945\n",
      "Epoch 22/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.2680 - acc: 0.8989 - val_loss: 0.5395 - val_acc: 0.7969\n",
      "Epoch 23/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.2623 - acc: 0.9018 - val_loss: 0.5512 - val_acc: 0.8030\n",
      "Epoch 24/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.2531 - acc: 0.9034 - val_loss: 0.5337 - val_acc: 0.8151\n",
      "Epoch 25/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.2431 - acc: 0.9071 - val_loss: 0.5403 - val_acc: 0.8217\n",
      "Epoch 26/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.2368 - acc: 0.9114 - val_loss: 0.5557 - val_acc: 0.8194\n",
      "Epoch 27/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.2241 - acc: 0.9172 - val_loss: 0.5313 - val_acc: 0.8235\n",
      "Epoch 28/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.2210 - acc: 0.9171 - val_loss: 0.5501 - val_acc: 0.8231\n",
      "Epoch 29/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.2133 - acc: 0.9195 - val_loss: 0.4909 - val_acc: 0.8346\n",
      "Epoch 30/400\n",
      "40350/40350 [==============================] - 9s 227us/sample - loss: 0.2092 - acc: 0.9201 - val_loss: 0.5013 - val_acc: 0.8352\n",
      "Epoch 31/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.1988 - acc: 0.9256 - val_loss: 0.5076 - val_acc: 0.8325\n",
      "Epoch 32/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1942 - acc: 0.9270 - val_loss: 0.5141 - val_acc: 0.8315\n",
      "Epoch 33/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1905 - acc: 0.9291 - val_loss: 0.5242 - val_acc: 0.8345\n",
      "Epoch 34/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.1844 - acc: 0.9305 - val_loss: 0.5200 - val_acc: 0.8367\n",
      "Epoch 35/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1818 - acc: 0.9314 - val_loss: 0.5069 - val_acc: 0.8409\n",
      "Epoch 36/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1737 - acc: 0.9343 - val_loss: 0.4918 - val_acc: 0.8471\n",
      "Epoch 37/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.1705 - acc: 0.9354 - val_loss: 0.5066 - val_acc: 0.8391\n",
      "Epoch 38/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1671 - acc: 0.9363 - val_loss: 0.5233 - val_acc: 0.8355\n",
      "Epoch 39/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1629 - acc: 0.9382 - val_loss: 0.5146 - val_acc: 0.8444\n",
      "Epoch 40/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1563 - acc: 0.9413 - val_loss: 0.5030 - val_acc: 0.8437\n",
      "Epoch 41/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1558 - acc: 0.9414 - val_loss: 0.5119 - val_acc: 0.8392\n",
      "Epoch 42/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1518 - acc: 0.9438 - val_loss: 0.5019 - val_acc: 0.8437\n",
      "Epoch 43/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1465 - acc: 0.9444 - val_loss: 0.4990 - val_acc: 0.8435\n",
      "Epoch 44/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1492 - acc: 0.9437 - val_loss: 0.4946 - val_acc: 0.8492\n",
      "Epoch 45/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1377 - acc: 0.9489 - val_loss: 0.5337 - val_acc: 0.8461\n",
      "Epoch 46/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.1398 - acc: 0.9474 - val_loss: 0.5096 - val_acc: 0.8481\n",
      "Epoch 47/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1355 - acc: 0.9487 - val_loss: 0.5240 - val_acc: 0.8493\n",
      "Epoch 48/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.1288 - acc: 0.9517 - val_loss: 0.5386 - val_acc: 0.8449\n",
      "Epoch 49/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1271 - acc: 0.9510 - val_loss: 0.5141 - val_acc: 0.8474\n",
      "Epoch 50/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1271 - acc: 0.9529 - val_loss: 0.5270 - val_acc: 0.8534\n",
      "Epoch 51/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1241 - acc: 0.9527 - val_loss: 0.5191 - val_acc: 0.8520\n",
      "Epoch 52/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1198 - acc: 0.9545 - val_loss: 0.5188 - val_acc: 0.8533\n",
      "Epoch 53/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1175 - acc: 0.9549 - val_loss: 0.5110 - val_acc: 0.8512\n",
      "Epoch 54/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1151 - acc: 0.9559 - val_loss: 0.5680 - val_acc: 0.8511\n",
      "Epoch 55/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1169 - acc: 0.9555 - val_loss: 0.5221 - val_acc: 0.8546\n",
      "Epoch 56/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1130 - acc: 0.9557 - val_loss: 0.5041 - val_acc: 0.8590\n",
      "Epoch 57/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1097 - acc: 0.9573 - val_loss: 0.5303 - val_acc: 0.8573\n",
      "Epoch 58/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1103 - acc: 0.9577 - val_loss: 0.5223 - val_acc: 0.8603\n",
      "Epoch 59/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.1064 - acc: 0.9603 - val_loss: 0.5178 - val_acc: 0.8597\n",
      "Epoch 60/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.1036 - acc: 0.9607 - val_loss: 0.5366 - val_acc: 0.8607\n",
      "Epoch 61/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.1020 - acc: 0.9606 - val_loss: 0.5455 - val_acc: 0.8601\n",
      "Epoch 62/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0987 - acc: 0.9620 - val_loss: 0.5361 - val_acc: 0.8625\n",
      "Epoch 63/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1018 - acc: 0.9611 - val_loss: 0.5349 - val_acc: 0.8663\n",
      "Epoch 64/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.1000 - acc: 0.9629 - val_loss: 0.5218 - val_acc: 0.8613\n",
      "Epoch 65/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0960 - acc: 0.9646 - val_loss: 0.5348 - val_acc: 0.8612\n",
      "Epoch 66/400\n",
      "40350/40350 [==============================] - 11s 268us/sample - loss: 0.0966 - acc: 0.9624 - val_loss: 0.5249 - val_acc: 0.8637\n",
      "Epoch 67/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0961 - acc: 0.9627 - val_loss: 0.5282 - val_acc: 0.8633\n",
      "Epoch 68/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0957 - acc: 0.9630 - val_loss: 0.5303 - val_acc: 0.8635\n",
      "Epoch 69/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0923 - acc: 0.9646 - val_loss: 0.5039 - val_acc: 0.8656\n",
      "Epoch 70/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0886 - acc: 0.9653 - val_loss: 0.5164 - val_acc: 0.8673\n",
      "Epoch 71/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0877 - acc: 0.9663 - val_loss: 0.5352 - val_acc: 0.8630\n",
      "Epoch 72/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0886 - acc: 0.9659 - val_loss: 0.5433 - val_acc: 0.8642\n",
      "Epoch 73/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0868 - acc: 0.9673 - val_loss: 0.5247 - val_acc: 0.8645\n",
      "Epoch 74/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0875 - acc: 0.9660 - val_loss: 0.5039 - val_acc: 0.8678\n",
      "Epoch 75/400\n",
      "40350/40350 [==============================] - 9s 228us/sample - loss: 0.0876 - acc: 0.9660 - val_loss: 0.5134 - val_acc: 0.8660\n",
      "Epoch 76/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0859 - acc: 0.9672 - val_loss: 0.5115 - val_acc: 0.8723\n",
      "Epoch 77/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0853 - acc: 0.9671 - val_loss: 0.5245 - val_acc: 0.8672\n",
      "Epoch 78/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0826 - acc: 0.9683 - val_loss: 0.5101 - val_acc: 0.8669\n",
      "Epoch 79/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0789 - acc: 0.9690 - val_loss: 0.5413 - val_acc: 0.8661\n",
      "Epoch 80/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0787 - acc: 0.9698 - val_loss: 0.5423 - val_acc: 0.8650\n",
      "Epoch 81/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0798 - acc: 0.9690 - val_loss: 0.5498 - val_acc: 0.8668\n",
      "Epoch 82/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0772 - acc: 0.9695 - val_loss: 0.5624 - val_acc: 0.8625\n",
      "Epoch 83/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0795 - acc: 0.9700 - val_loss: 0.5473 - val_acc: 0.8648\n",
      "Epoch 84/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0774 - acc: 0.9695 - val_loss: 0.5615 - val_acc: 0.8620\n",
      "Epoch 85/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0785 - acc: 0.9696 - val_loss: 0.5260 - val_acc: 0.8688\n",
      "Epoch 86/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0772 - acc: 0.9700 - val_loss: 0.5673 - val_acc: 0.8620\n",
      "Epoch 87/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0744 - acc: 0.9714 - val_loss: 0.5529 - val_acc: 0.8704\n",
      "Epoch 88/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0732 - acc: 0.9717 - val_loss: 0.5359 - val_acc: 0.8692\n",
      "Epoch 89/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0751 - acc: 0.9714 - val_loss: 0.5486 - val_acc: 0.8670\n",
      "Epoch 90/400\n",
      "40350/40350 [==============================] - 9s 227us/sample - loss: 0.0725 - acc: 0.9714 - val_loss: 0.5437 - val_acc: 0.8736\n",
      "Epoch 91/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0733 - acc: 0.9722 - val_loss: 0.5286 - val_acc: 0.8732\n",
      "Epoch 92/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0723 - acc: 0.9713 - val_loss: 0.5302 - val_acc: 0.8710\n",
      "Epoch 93/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0671 - acc: 0.9732 - val_loss: 0.5480 - val_acc: 0.8730\n",
      "Epoch 94/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0689 - acc: 0.9730 - val_loss: 0.5420 - val_acc: 0.8760\n",
      "Epoch 95/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0709 - acc: 0.9725 - val_loss: 0.5391 - val_acc: 0.8702\n",
      "Epoch 96/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0693 - acc: 0.9725 - val_loss: 0.5499 - val_acc: 0.8722\n",
      "Epoch 97/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0692 - acc: 0.9736 - val_loss: 0.5721 - val_acc: 0.8692\n",
      "Epoch 98/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0688 - acc: 0.9732 - val_loss: 0.5646 - val_acc: 0.8688\n",
      "Epoch 99/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0646 - acc: 0.9749 - val_loss: 0.5720 - val_acc: 0.8689\n",
      "Epoch 100/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0635 - acc: 0.9747 - val_loss: 0.5602 - val_acc: 0.8706\n",
      "Epoch 101/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0643 - acc: 0.9751 - val_loss: 0.5729 - val_acc: 0.8694\n",
      "Epoch 102/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0644 - acc: 0.9745 - val_loss: 0.5872 - val_acc: 0.8694\n",
      "Epoch 103/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0632 - acc: 0.9760 - val_loss: 0.5496 - val_acc: 0.8722\n",
      "Epoch 104/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0655 - acc: 0.9753 - val_loss: 0.5580 - val_acc: 0.8710\n",
      "Epoch 105/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0624 - acc: 0.9762 - val_loss: 0.5587 - val_acc: 0.8710\n",
      "Epoch 106/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0614 - acc: 0.9762 - val_loss: 0.5672 - val_acc: 0.8711\n",
      "Epoch 107/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0606 - acc: 0.9765 - val_loss: 0.5571 - val_acc: 0.8735\n",
      "Epoch 108/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0618 - acc: 0.9760 - val_loss: 0.5699 - val_acc: 0.8716\n",
      "Epoch 109/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0599 - acc: 0.9768 - val_loss: 0.5687 - val_acc: 0.8685\n",
      "Epoch 110/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0576 - acc: 0.9780 - val_loss: 0.5759 - val_acc: 0.8700\n",
      "Epoch 111/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0602 - acc: 0.9771 - val_loss: 0.5497 - val_acc: 0.8684\n",
      "Epoch 112/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0576 - acc: 0.9773 - val_loss: 0.5549 - val_acc: 0.8736\n",
      "Epoch 113/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0577 - acc: 0.9775 - val_loss: 0.5807 - val_acc: 0.8715\n",
      "Epoch 114/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0581 - acc: 0.9776 - val_loss: 0.5416 - val_acc: 0.8737\n",
      "Epoch 115/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0561 - acc: 0.9776 - val_loss: 0.5709 - val_acc: 0.8746\n",
      "Epoch 116/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0570 - acc: 0.9781 - val_loss: 0.5693 - val_acc: 0.8752\n",
      "Epoch 117/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0566 - acc: 0.9782 - val_loss: 0.5650 - val_acc: 0.8759\n",
      "Epoch 118/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0568 - acc: 0.9788 - val_loss: 0.5889 - val_acc: 0.8675\n",
      "Epoch 119/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0538 - acc: 0.9795 - val_loss: 0.5609 - val_acc: 0.8729\n",
      "Epoch 120/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0542 - acc: 0.9787 - val_loss: 0.5578 - val_acc: 0.8780\n",
      "Epoch 121/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0546 - acc: 0.9798 - val_loss: 0.5691 - val_acc: 0.8737\n",
      "Epoch 122/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0547 - acc: 0.9790 - val_loss: 0.5684 - val_acc: 0.8734\n",
      "Epoch 123/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0574 - acc: 0.9790 - val_loss: 0.5524 - val_acc: 0.8769\n",
      "Epoch 124/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0549 - acc: 0.9792 - val_loss: 0.5704 - val_acc: 0.8693\n",
      "Epoch 125/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0526 - acc: 0.9792 - val_loss: 0.5928 - val_acc: 0.8713\n",
      "Epoch 126/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0524 - acc: 0.9802 - val_loss: 0.5636 - val_acc: 0.8756\n",
      "Epoch 127/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0501 - acc: 0.9804 - val_loss: 0.5818 - val_acc: 0.8753\n",
      "Epoch 128/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0536 - acc: 0.9792 - val_loss: 0.5801 - val_acc: 0.8715\n",
      "Epoch 129/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0530 - acc: 0.9792 - val_loss: 0.5624 - val_acc: 0.8748\n",
      "Epoch 130/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0511 - acc: 0.9806 - val_loss: 0.5916 - val_acc: 0.8703\n",
      "Epoch 131/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0513 - acc: 0.9801 - val_loss: 0.5963 - val_acc: 0.8723\n",
      "Epoch 132/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0514 - acc: 0.9801 - val_loss: 0.5856 - val_acc: 0.8773\n",
      "Epoch 133/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0524 - acc: 0.9801 - val_loss: 0.5766 - val_acc: 0.8778\n",
      "Epoch 134/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0490 - acc: 0.9812 - val_loss: 0.5831 - val_acc: 0.8780\n",
      "Epoch 135/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0492 - acc: 0.9812 - val_loss: 0.5868 - val_acc: 0.8763\n",
      "Epoch 136/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0509 - acc: 0.9811 - val_loss: 0.5817 - val_acc: 0.8783\n",
      "Epoch 137/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0488 - acc: 0.9816 - val_loss: 0.6028 - val_acc: 0.8754\n",
      "Epoch 138/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0479 - acc: 0.9815 - val_loss: 0.6116 - val_acc: 0.8762\n",
      "Epoch 139/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0487 - acc: 0.9823 - val_loss: 0.6129 - val_acc: 0.8729\n",
      "Epoch 140/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0480 - acc: 0.9817 - val_loss: 0.6142 - val_acc: 0.8709\n",
      "Epoch 141/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0470 - acc: 0.9818 - val_loss: 0.6068 - val_acc: 0.8731\n",
      "Epoch 142/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0472 - acc: 0.9813 - val_loss: 0.6146 - val_acc: 0.8778\n",
      "Epoch 143/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0442 - acc: 0.9829 - val_loss: 0.6125 - val_acc: 0.8787\n",
      "Epoch 144/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0463 - acc: 0.9820 - val_loss: 0.6259 - val_acc: 0.8749\n",
      "Epoch 145/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0465 - acc: 0.9823 - val_loss: 0.6375 - val_acc: 0.8733\n",
      "Epoch 146/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0462 - acc: 0.9823 - val_loss: 0.6081 - val_acc: 0.8764\n",
      "Epoch 147/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0439 - acc: 0.9833 - val_loss: 0.6136 - val_acc: 0.8777\n",
      "Epoch 148/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0457 - acc: 0.9827 - val_loss: 0.6113 - val_acc: 0.8784\n",
      "Epoch 149/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0447 - acc: 0.9831 - val_loss: 0.5905 - val_acc: 0.8795\n",
      "Epoch 150/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0461 - acc: 0.9822 - val_loss: 0.6098 - val_acc: 0.8763\n",
      "Epoch 151/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0455 - acc: 0.9825 - val_loss: 0.5929 - val_acc: 0.8814\n",
      "Epoch 152/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0440 - acc: 0.9831 - val_loss: 0.6091 - val_acc: 0.8733\n",
      "Epoch 153/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0428 - acc: 0.9832 - val_loss: 0.6383 - val_acc: 0.8765\n",
      "Epoch 154/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0432 - acc: 0.9836 - val_loss: 0.6456 - val_acc: 0.8751\n",
      "Epoch 155/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0444 - acc: 0.9831 - val_loss: 0.6311 - val_acc: 0.8746\n",
      "Epoch 156/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0440 - acc: 0.9836 - val_loss: 0.6071 - val_acc: 0.8765\n",
      "Epoch 157/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0431 - acc: 0.9836 - val_loss: 0.6147 - val_acc: 0.8748\n",
      "Epoch 158/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0421 - acc: 0.9833 - val_loss: 0.6118 - val_acc: 0.8791\n",
      "Epoch 159/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0446 - acc: 0.9829 - val_loss: 0.6001 - val_acc: 0.8792\n",
      "Epoch 160/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0403 - acc: 0.9843 - val_loss: 0.6251 - val_acc: 0.8792\n",
      "Epoch 161/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0426 - acc: 0.9838 - val_loss: 0.6012 - val_acc: 0.8782\n",
      "Epoch 162/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0410 - acc: 0.9843 - val_loss: 0.6234 - val_acc: 0.8816\n",
      "Epoch 163/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0430 - acc: 0.9840 - val_loss: 0.6196 - val_acc: 0.8766\n",
      "Epoch 164/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0410 - acc: 0.9841 - val_loss: 0.6402 - val_acc: 0.8755\n",
      "Epoch 165/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0416 - acc: 0.9840 - val_loss: 0.6154 - val_acc: 0.8803\n",
      "Epoch 166/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0402 - acc: 0.9846 - val_loss: 0.6234 - val_acc: 0.8781\n",
      "Epoch 167/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0413 - acc: 0.9842 - val_loss: 0.6391 - val_acc: 0.8788\n",
      "Epoch 168/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0407 - acc: 0.9841 - val_loss: 0.6064 - val_acc: 0.8779\n",
      "Epoch 169/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0401 - acc: 0.9844 - val_loss: 0.6203 - val_acc: 0.8805\n",
      "Epoch 170/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0403 - acc: 0.9844 - val_loss: 0.6350 - val_acc: 0.8783\n",
      "Epoch 171/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0398 - acc: 0.9850 - val_loss: 0.6214 - val_acc: 0.8797\n",
      "Epoch 172/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0386 - acc: 0.9851 - val_loss: 0.6468 - val_acc: 0.8764\n",
      "Epoch 173/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0380 - acc: 0.9854 - val_loss: 0.6270 - val_acc: 0.8814\n",
      "Epoch 174/400\n",
      "40350/40350 [==============================] - 9s 221us/sample - loss: 0.0392 - acc: 0.9853 - val_loss: 0.6333 - val_acc: 0.8821\n",
      "Epoch 175/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0393 - acc: 0.9851 - val_loss: 0.6432 - val_acc: 0.8807\n",
      "Epoch 176/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0380 - acc: 0.9858 - val_loss: 0.6676 - val_acc: 0.8773\n",
      "Epoch 177/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0383 - acc: 0.9850 - val_loss: 0.6270 - val_acc: 0.8808\n",
      "Epoch 178/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0376 - acc: 0.9865 - val_loss: 0.6332 - val_acc: 0.8827\n",
      "Epoch 179/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0384 - acc: 0.9859 - val_loss: 0.6404 - val_acc: 0.8827\n",
      "Epoch 180/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0382 - acc: 0.9851 - val_loss: 0.6400 - val_acc: 0.8810\n",
      "Epoch 181/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0364 - acc: 0.9860 - val_loss: 0.6330 - val_acc: 0.8801\n",
      "Epoch 182/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0393 - acc: 0.9855 - val_loss: 0.6295 - val_acc: 0.8833\n",
      "Epoch 183/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0340 - acc: 0.9871 - val_loss: 0.6897 - val_acc: 0.8780\n",
      "Epoch 184/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0393 - acc: 0.9857 - val_loss: 0.6685 - val_acc: 0.8759\n",
      "Epoch 185/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0353 - acc: 0.9866 - val_loss: 0.6553 - val_acc: 0.8772\n",
      "Epoch 186/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0386 - acc: 0.9860 - val_loss: 0.6430 - val_acc: 0.8828\n",
      "Epoch 187/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0368 - acc: 0.9863 - val_loss: 0.6378 - val_acc: 0.8804\n",
      "Epoch 188/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0366 - acc: 0.9860 - val_loss: 0.6632 - val_acc: 0.8794\n",
      "Epoch 189/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0355 - acc: 0.9866 - val_loss: 0.6408 - val_acc: 0.8816\n",
      "Epoch 190/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0363 - acc: 0.9865 - val_loss: 0.6547 - val_acc: 0.8812\n",
      "Epoch 191/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0368 - acc: 0.9862 - val_loss: 0.6190 - val_acc: 0.8857\n",
      "Epoch 192/400\n",
      "40350/40350 [==============================] - 9s 221us/sample - loss: 0.0353 - acc: 0.9864 - val_loss: 0.6197 - val_acc: 0.8886\n",
      "Epoch 193/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0329 - acc: 0.9876 - val_loss: 0.6426 - val_acc: 0.8820\n",
      "Epoch 194/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0351 - acc: 0.9873 - val_loss: 0.6196 - val_acc: 0.8838\n",
      "Epoch 195/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0335 - acc: 0.9875 - val_loss: 0.6686 - val_acc: 0.8798\n",
      "Epoch 196/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0339 - acc: 0.9875 - val_loss: 0.6634 - val_acc: 0.8793\n",
      "Epoch 197/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0338 - acc: 0.9877 - val_loss: 0.6559 - val_acc: 0.8827\n",
      "Epoch 198/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0361 - acc: 0.9871 - val_loss: 0.6432 - val_acc: 0.8848\n",
      "Epoch 199/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0340 - acc: 0.9871 - val_loss: 0.6276 - val_acc: 0.8867\n",
      "Epoch 200/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0351 - acc: 0.9874 - val_loss: 0.6246 - val_acc: 0.8860\n",
      "Epoch 201/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0349 - acc: 0.9869 - val_loss: 0.6132 - val_acc: 0.8852\n",
      "Epoch 202/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0369 - acc: 0.9860 - val_loss: 0.6352 - val_acc: 0.8807\n",
      "Epoch 203/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0337 - acc: 0.9874 - val_loss: 0.6194 - val_acc: 0.8865\n",
      "Epoch 204/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0334 - acc: 0.9881 - val_loss: 0.6257 - val_acc: 0.8858\n",
      "Epoch 205/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0331 - acc: 0.9875 - val_loss: 0.6156 - val_acc: 0.8826\n",
      "Epoch 206/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0327 - acc: 0.9877 - val_loss: 0.6161 - val_acc: 0.8830\n",
      "Epoch 207/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0360 - acc: 0.9861 - val_loss: 0.6138 - val_acc: 0.8839\n",
      "Epoch 208/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0332 - acc: 0.9875 - val_loss: 0.6250 - val_acc: 0.8852\n",
      "Epoch 209/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0343 - acc: 0.9875 - val_loss: 0.6159 - val_acc: 0.8836\n",
      "Epoch 210/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0317 - acc: 0.9879 - val_loss: 0.6291 - val_acc: 0.8817\n",
      "Epoch 211/400\n",
      "40350/40350 [==============================] - 9s 221us/sample - loss: 0.0326 - acc: 0.9879 - val_loss: 0.6102 - val_acc: 0.8853\n",
      "Epoch 212/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0347 - acc: 0.9867 - val_loss: 0.6288 - val_acc: 0.8857\n",
      "Epoch 213/400\n",
      "40350/40350 [==============================] - 9s 221us/sample - loss: 0.0291 - acc: 0.9890 - val_loss: 0.6456 - val_acc: 0.8878\n",
      "Epoch 214/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0330 - acc: 0.9883 - val_loss: 0.6172 - val_acc: 0.8873\n",
      "Epoch 215/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0302 - acc: 0.9885 - val_loss: 0.6750 - val_acc: 0.8797\n",
      "Epoch 216/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0304 - acc: 0.9890 - val_loss: 0.6427 - val_acc: 0.8836\n",
      "Epoch 217/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0314 - acc: 0.9883 - val_loss: 0.6412 - val_acc: 0.8802\n",
      "Epoch 218/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0322 - acc: 0.9879 - val_loss: 0.6439 - val_acc: 0.8826\n",
      "Epoch 219/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0286 - acc: 0.9893 - val_loss: 0.6645 - val_acc: 0.8833\n",
      "Epoch 220/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0305 - acc: 0.9885 - val_loss: 0.6635 - val_acc: 0.8844\n",
      "Epoch 221/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0302 - acc: 0.9891 - val_loss: 0.6641 - val_acc: 0.8832\n",
      "Epoch 222/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0330 - acc: 0.9876 - val_loss: 0.6722 - val_acc: 0.8819\n",
      "Epoch 223/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0291 - acc: 0.9894 - val_loss: 0.6605 - val_acc: 0.8845\n",
      "Epoch 224/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0327 - acc: 0.9879 - val_loss: 0.6191 - val_acc: 0.8837\n",
      "Epoch 225/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0293 - acc: 0.9890 - val_loss: 0.6703 - val_acc: 0.8847\n",
      "Epoch 226/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0311 - acc: 0.9889 - val_loss: 0.6705 - val_acc: 0.8851\n",
      "Epoch 227/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0284 - acc: 0.9897 - val_loss: 0.6548 - val_acc: 0.8857\n",
      "Epoch 228/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0298 - acc: 0.9890 - val_loss: 0.6503 - val_acc: 0.8836\n",
      "Epoch 229/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0298 - acc: 0.9889 - val_loss: 0.6756 - val_acc: 0.8847\n",
      "Epoch 230/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0300 - acc: 0.9884 - val_loss: 0.6818 - val_acc: 0.8853\n",
      "Epoch 231/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0306 - acc: 0.9887 - val_loss: 0.6518 - val_acc: 0.8866\n",
      "Epoch 232/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0278 - acc: 0.9895 - val_loss: 0.6752 - val_acc: 0.8838\n",
      "Epoch 233/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0279 - acc: 0.9901 - val_loss: 0.6835 - val_acc: 0.8842\n",
      "Epoch 234/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0297 - acc: 0.9890 - val_loss: 0.6689 - val_acc: 0.8837\n",
      "Epoch 235/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0306 - acc: 0.9887 - val_loss: 0.6389 - val_acc: 0.8822\n",
      "Epoch 236/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0289 - acc: 0.9898 - val_loss: 0.6867 - val_acc: 0.8806\n",
      "Epoch 237/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0316 - acc: 0.9887 - val_loss: 0.6496 - val_acc: 0.8811\n",
      "Epoch 238/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0285 - acc: 0.9897 - val_loss: 0.6485 - val_acc: 0.8824\n",
      "Epoch 239/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0295 - acc: 0.9895 - val_loss: 0.6355 - val_acc: 0.8843\n",
      "Epoch 240/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0297 - acc: 0.9892 - val_loss: 0.6642 - val_acc: 0.8837\n",
      "Epoch 241/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0284 - acc: 0.9901 - val_loss: 0.6712 - val_acc: 0.8853\n",
      "Epoch 242/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0288 - acc: 0.9897 - val_loss: 0.6483 - val_acc: 0.8861\n",
      "Epoch 243/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0295 - acc: 0.9891 - val_loss: 0.6479 - val_acc: 0.8852\n",
      "Epoch 244/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0278 - acc: 0.9901 - val_loss: 0.6519 - val_acc: 0.8866\n",
      "Epoch 245/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0275 - acc: 0.9899 - val_loss: 0.6557 - val_acc: 0.8848\n",
      "Epoch 246/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0270 - acc: 0.9903 - val_loss: 0.6454 - val_acc: 0.8862\n",
      "Epoch 247/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0265 - acc: 0.9912 - val_loss: 0.6618 - val_acc: 0.8885\n",
      "Epoch 248/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0270 - acc: 0.9902 - val_loss: 0.6435 - val_acc: 0.8854\n",
      "Epoch 249/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0259 - acc: 0.9908 - val_loss: 0.6747 - val_acc: 0.8830\n",
      "Epoch 250/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0265 - acc: 0.9904 - val_loss: 0.6443 - val_acc: 0.8835\n",
      "Epoch 251/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0254 - acc: 0.9900 - val_loss: 0.6581 - val_acc: 0.8848\n",
      "Epoch 252/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0275 - acc: 0.9901 - val_loss: 0.6363 - val_acc: 0.8871\n",
      "Epoch 253/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0280 - acc: 0.9904 - val_loss: 0.6431 - val_acc: 0.8860\n",
      "Epoch 254/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0257 - acc: 0.9910 - val_loss: 0.6633 - val_acc: 0.8869\n",
      "Epoch 255/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0273 - acc: 0.9900 - val_loss: 0.6353 - val_acc: 0.8869\n",
      "Epoch 256/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0264 - acc: 0.9910 - val_loss: 0.6511 - val_acc: 0.8869\n",
      "Epoch 257/400\n",
      "40350/40350 [==============================] - 9s 221us/sample - loss: 0.0255 - acc: 0.9910 - val_loss: 0.6412 - val_acc: 0.8872\n",
      "Epoch 258/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0274 - acc: 0.9894 - val_loss: 0.6510 - val_acc: 0.8893\n",
      "Epoch 259/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0274 - acc: 0.9904 - val_loss: 0.6259 - val_acc: 0.8883\n",
      "Epoch 260/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0261 - acc: 0.9905 - val_loss: 0.6315 - val_acc: 0.8916\n",
      "Epoch 261/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0254 - acc: 0.9909 - val_loss: 0.6609 - val_acc: 0.8877\n",
      "Epoch 262/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0256 - acc: 0.9909 - val_loss: 0.6523 - val_acc: 0.8886\n",
      "Epoch 263/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0249 - acc: 0.9913 - val_loss: 0.6405 - val_acc: 0.8887\n",
      "Epoch 264/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0267 - acc: 0.9907 - val_loss: 0.6430 - val_acc: 0.8857\n",
      "Epoch 265/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0256 - acc: 0.9913 - val_loss: 0.6482 - val_acc: 0.8862\n",
      "Epoch 266/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0252 - acc: 0.9906 - val_loss: 0.6484 - val_acc: 0.8870\n",
      "Epoch 267/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0263 - acc: 0.9910 - val_loss: 0.6376 - val_acc: 0.8880\n",
      "Epoch 268/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0233 - acc: 0.9913 - val_loss: 0.6768 - val_acc: 0.8847\n",
      "Epoch 269/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0264 - acc: 0.9904 - val_loss: 0.6447 - val_acc: 0.8872\n",
      "Epoch 270/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0246 - acc: 0.9917 - val_loss: 0.6534 - val_acc: 0.8875\n",
      "Epoch 271/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0266 - acc: 0.9910 - val_loss: 0.6274 - val_acc: 0.8900\n",
      "Epoch 272/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0244 - acc: 0.9916 - val_loss: 0.6119 - val_acc: 0.8948\n",
      "Epoch 273/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0257 - acc: 0.9908 - val_loss: 0.6472 - val_acc: 0.8879\n",
      "Epoch 274/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0267 - acc: 0.9910 - val_loss: 0.6604 - val_acc: 0.8881\n",
      "Epoch 275/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0249 - acc: 0.9913 - val_loss: 0.6422 - val_acc: 0.8897\n",
      "Epoch 276/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0224 - acc: 0.9922 - val_loss: 0.6605 - val_acc: 0.8864\n",
      "Epoch 277/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0260 - acc: 0.9909 - val_loss: 0.6519 - val_acc: 0.8867\n",
      "Epoch 278/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0245 - acc: 0.9911 - val_loss: 0.6472 - val_acc: 0.8875\n",
      "Epoch 279/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0254 - acc: 0.9919 - val_loss: 0.6377 - val_acc: 0.8874\n",
      "Epoch 280/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0232 - acc: 0.9918 - val_loss: 0.6739 - val_acc: 0.8831\n",
      "Epoch 281/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0230 - acc: 0.9919 - val_loss: 0.6499 - val_acc: 0.8865\n",
      "Epoch 282/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0241 - acc: 0.9914 - val_loss: 0.6443 - val_acc: 0.8869\n",
      "Epoch 283/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0243 - acc: 0.9911 - val_loss: 0.6469 - val_acc: 0.8887\n",
      "Epoch 284/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0245 - acc: 0.9914 - val_loss: 0.6504 - val_acc: 0.8889\n",
      "Epoch 285/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0231 - acc: 0.9917 - val_loss: 0.6579 - val_acc: 0.8836\n",
      "Epoch 286/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0245 - acc: 0.9914 - val_loss: 0.6392 - val_acc: 0.8884\n",
      "Epoch 287/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0261 - acc: 0.9909 - val_loss: 0.6320 - val_acc: 0.8858\n",
      "Epoch 288/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0238 - acc: 0.9917 - val_loss: 0.6348 - val_acc: 0.8899\n",
      "Epoch 289/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0237 - acc: 0.9920 - val_loss: 0.6260 - val_acc: 0.8921\n",
      "Epoch 290/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0239 - acc: 0.9912 - val_loss: 0.6283 - val_acc: 0.8892\n",
      "Epoch 291/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0241 - acc: 0.9916 - val_loss: 0.6317 - val_acc: 0.8900\n",
      "Epoch 292/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0249 - acc: 0.9913 - val_loss: 0.6371 - val_acc: 0.8891\n",
      "Epoch 293/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0222 - acc: 0.9923 - val_loss: 0.6660 - val_acc: 0.8862\n",
      "Epoch 294/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0211 - acc: 0.9920 - val_loss: 0.6678 - val_acc: 0.8852\n",
      "Epoch 295/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0234 - acc: 0.9917 - val_loss: 0.6608 - val_acc: 0.8836\n",
      "Epoch 296/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0231 - acc: 0.9922 - val_loss: 0.6528 - val_acc: 0.8873\n",
      "Epoch 297/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0243 - acc: 0.9914 - val_loss: 0.6241 - val_acc: 0.8909\n",
      "Epoch 298/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0218 - acc: 0.9924 - val_loss: 0.6679 - val_acc: 0.8869\n",
      "Epoch 299/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0228 - acc: 0.9926 - val_loss: 0.6821 - val_acc: 0.8856\n",
      "Epoch 300/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0225 - acc: 0.9922 - val_loss: 0.6582 - val_acc: 0.8892\n",
      "Epoch 301/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0220 - acc: 0.9928 - val_loss: 0.6582 - val_acc: 0.8873\n",
      "Epoch 302/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0226 - acc: 0.9929 - val_loss: 0.6582 - val_acc: 0.8872\n",
      "Epoch 303/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0232 - acc: 0.9920 - val_loss: 0.6562 - val_acc: 0.8884\n",
      "Epoch 304/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0233 - acc: 0.9922 - val_loss: 0.6300 - val_acc: 0.8871\n",
      "Epoch 305/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0229 - acc: 0.9917 - val_loss: 0.6343 - val_acc: 0.8877\n",
      "Epoch 306/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0207 - acc: 0.9924 - val_loss: 0.6713 - val_acc: 0.8837\n",
      "Epoch 307/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0215 - acc: 0.9928 - val_loss: 0.6761 - val_acc: 0.8853\n",
      "Epoch 308/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0217 - acc: 0.9927 - val_loss: 0.6835 - val_acc: 0.8847\n",
      "Epoch 309/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0227 - acc: 0.9925 - val_loss: 0.6495 - val_acc: 0.8871\n",
      "Epoch 310/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0211 - acc: 0.9925 - val_loss: 0.6367 - val_acc: 0.8872\n",
      "Epoch 311/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0214 - acc: 0.9925 - val_loss: 0.6542 - val_acc: 0.8884\n",
      "Epoch 312/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0204 - acc: 0.9932 - val_loss: 0.6632 - val_acc: 0.8873\n",
      "Epoch 313/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0231 - acc: 0.9919 - val_loss: 0.6775 - val_acc: 0.8863\n",
      "Epoch 314/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0216 - acc: 0.9928 - val_loss: 0.6692 - val_acc: 0.8899\n",
      "Epoch 315/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0220 - acc: 0.9926 - val_loss: 0.6133 - val_acc: 0.8916\n",
      "Epoch 316/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0210 - acc: 0.9928 - val_loss: 0.6382 - val_acc: 0.8872\n",
      "Epoch 317/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0222 - acc: 0.9921 - val_loss: 0.6441 - val_acc: 0.8854\n",
      "Epoch 318/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0212 - acc: 0.9926 - val_loss: 0.6604 - val_acc: 0.8848\n",
      "Epoch 319/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0223 - acc: 0.9924 - val_loss: 0.6258 - val_acc: 0.8911\n",
      "Epoch 320/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0224 - acc: 0.9922 - val_loss: 0.6431 - val_acc: 0.8903\n",
      "Epoch 321/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0220 - acc: 0.9924 - val_loss: 0.6440 - val_acc: 0.8891\n",
      "Epoch 322/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0188 - acc: 0.9935 - val_loss: 0.6290 - val_acc: 0.8906\n",
      "Epoch 323/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0215 - acc: 0.9925 - val_loss: 0.6609 - val_acc: 0.8864\n",
      "Epoch 324/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0198 - acc: 0.9935 - val_loss: 0.6816 - val_acc: 0.8851\n",
      "Epoch 325/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0212 - acc: 0.9930 - val_loss: 0.6401 - val_acc: 0.8855\n",
      "Epoch 326/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0224 - acc: 0.9923 - val_loss: 0.6149 - val_acc: 0.8915\n",
      "Epoch 327/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0220 - acc: 0.9926 - val_loss: 0.6491 - val_acc: 0.8857\n",
      "Epoch 328/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0221 - acc: 0.9923 - val_loss: 0.6239 - val_acc: 0.8926\n",
      "Epoch 329/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0191 - acc: 0.9934 - val_loss: 0.6452 - val_acc: 0.8905\n",
      "Epoch 330/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0207 - acc: 0.9929 - val_loss: 0.6199 - val_acc: 0.8921\n",
      "Epoch 331/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0200 - acc: 0.9928 - val_loss: 0.6348 - val_acc: 0.8913\n",
      "Epoch 332/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0202 - acc: 0.9928 - val_loss: 0.6355 - val_acc: 0.8886\n",
      "Epoch 333/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0201 - acc: 0.9929 - val_loss: 0.6554 - val_acc: 0.8872\n",
      "Epoch 334/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0224 - acc: 0.9929 - val_loss: 0.6577 - val_acc: 0.8862\n",
      "Epoch 335/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0196 - acc: 0.9935 - val_loss: 0.6498 - val_acc: 0.8866\n",
      "Epoch 336/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0201 - acc: 0.9934 - val_loss: 0.6340 - val_acc: 0.8863\n",
      "Epoch 337/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0198 - acc: 0.9936 - val_loss: 0.6542 - val_acc: 0.8879\n",
      "Epoch 338/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0200 - acc: 0.9934 - val_loss: 0.6685 - val_acc: 0.8837\n",
      "Epoch 339/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0195 - acc: 0.9939 - val_loss: 0.6600 - val_acc: 0.8852\n",
      "Epoch 340/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0193 - acc: 0.9934 - val_loss: 0.6422 - val_acc: 0.8903\n",
      "Epoch 341/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0191 - acc: 0.9932 - val_loss: 0.6532 - val_acc: 0.8920\n",
      "Epoch 342/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0208 - acc: 0.9928 - val_loss: 0.6282 - val_acc: 0.8930\n",
      "Epoch 343/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0214 - acc: 0.9927 - val_loss: 0.6382 - val_acc: 0.8911\n",
      "Epoch 344/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0197 - acc: 0.9932 - val_loss: 0.6568 - val_acc: 0.8879\n",
      "Epoch 345/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0212 - acc: 0.9927 - val_loss: 0.6476 - val_acc: 0.8890\n",
      "Epoch 346/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0210 - acc: 0.9930 - val_loss: 0.6612 - val_acc: 0.8880\n",
      "Epoch 347/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0201 - acc: 0.9930 - val_loss: 0.6532 - val_acc: 0.8893\n",
      "Epoch 348/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0184 - acc: 0.9938 - val_loss: 0.6620 - val_acc: 0.8912\n",
      "Epoch 349/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0203 - acc: 0.9927 - val_loss: 0.6513 - val_acc: 0.8927\n",
      "Epoch 350/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0195 - acc: 0.9933 - val_loss: 0.6538 - val_acc: 0.8893\n",
      "Epoch 351/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0190 - acc: 0.9937 - val_loss: 0.6319 - val_acc: 0.8921\n",
      "Epoch 352/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0210 - acc: 0.9926 - val_loss: 0.6495 - val_acc: 0.8864\n",
      "Epoch 353/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0196 - acc: 0.9937 - val_loss: 0.6336 - val_acc: 0.8874\n",
      "Epoch 354/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0207 - acc: 0.9927 - val_loss: 0.6438 - val_acc: 0.8900\n",
      "Epoch 355/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0177 - acc: 0.9936 - val_loss: 0.6571 - val_acc: 0.8824\n",
      "Epoch 356/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0196 - acc: 0.9934 - val_loss: 0.6404 - val_acc: 0.8900\n",
      "Epoch 357/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0191 - acc: 0.9936 - val_loss: 0.6751 - val_acc: 0.8841\n",
      "Epoch 358/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0214 - acc: 0.9928 - val_loss: 0.6596 - val_acc: 0.8816\n",
      "Epoch 359/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0201 - acc: 0.9935 - val_loss: 0.6464 - val_acc: 0.8852\n",
      "Epoch 360/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0197 - acc: 0.9935 - val_loss: 0.6573 - val_acc: 0.8858\n",
      "Epoch 361/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0205 - acc: 0.9931 - val_loss: 0.6733 - val_acc: 0.8841\n",
      "Epoch 362/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0197 - acc: 0.9932 - val_loss: 0.6416 - val_acc: 0.8870\n",
      "Epoch 363/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0181 - acc: 0.9935 - val_loss: 0.6665 - val_acc: 0.8856\n",
      "Epoch 364/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0200 - acc: 0.9932 - val_loss: 0.6922 - val_acc: 0.8839\n",
      "Epoch 365/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0194 - acc: 0.9939 - val_loss: 0.6973 - val_acc: 0.8828\n",
      "Epoch 366/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0178 - acc: 0.9942 - val_loss: 0.6612 - val_acc: 0.8868\n",
      "Epoch 367/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0165 - acc: 0.9946 - val_loss: 0.6927 - val_acc: 0.8834\n",
      "Epoch 368/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0170 - acc: 0.9944 - val_loss: 0.6919 - val_acc: 0.8866\n",
      "Epoch 369/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0174 - acc: 0.9939 - val_loss: 0.6617 - val_acc: 0.8886\n",
      "Epoch 370/400\n",
      "40350/40350 [==============================] - 9s 222us/sample - loss: 0.0177 - acc: 0.9944 - val_loss: 0.6652 - val_acc: 0.8885\n",
      "Epoch 371/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0181 - acc: 0.9938 - val_loss: 0.6681 - val_acc: 0.8869\n",
      "Epoch 372/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0184 - acc: 0.9939 - val_loss: 0.6816 - val_acc: 0.8847\n",
      "Epoch 373/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0196 - acc: 0.9931 - val_loss: 0.6481 - val_acc: 0.8878\n",
      "Epoch 374/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0191 - acc: 0.9936 - val_loss: 0.6501 - val_acc: 0.8900\n",
      "Epoch 375/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0182 - acc: 0.9942 - val_loss: 0.6591 - val_acc: 0.8880\n",
      "Epoch 376/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0187 - acc: 0.9938 - val_loss: 0.6523 - val_acc: 0.8880\n",
      "Epoch 377/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0169 - acc: 0.9943 - val_loss: 0.6835 - val_acc: 0.8874\n",
      "Epoch 378/400\n",
      "40350/40350 [==============================] - 9s 226us/sample - loss: 0.0176 - acc: 0.9939 - val_loss: 0.6703 - val_acc: 0.8871\n",
      "Epoch 379/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0185 - acc: 0.9938 - val_loss: 0.6845 - val_acc: 0.8856\n",
      "Epoch 380/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0177 - acc: 0.9940 - val_loss: 0.6490 - val_acc: 0.8907\n",
      "Epoch 381/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0181 - acc: 0.9942 - val_loss: 0.6454 - val_acc: 0.8904\n",
      "Epoch 382/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0195 - acc: 0.9933 - val_loss: 0.6665 - val_acc: 0.8910\n",
      "Epoch 383/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0194 - acc: 0.9936 - val_loss: 0.6668 - val_acc: 0.8873\n",
      "Epoch 384/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0175 - acc: 0.9941 - val_loss: 0.6722 - val_acc: 0.8877\n",
      "Epoch 385/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0189 - acc: 0.9940 - val_loss: 0.6794 - val_acc: 0.8872\n",
      "Epoch 386/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0186 - acc: 0.9942 - val_loss: 0.6586 - val_acc: 0.8875\n",
      "Epoch 387/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0171 - acc: 0.9943 - val_loss: 0.6919 - val_acc: 0.8853\n",
      "Epoch 388/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0175 - acc: 0.9944 - val_loss: 0.6686 - val_acc: 0.8878\n",
      "Epoch 389/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0171 - acc: 0.9944 - val_loss: 0.6624 - val_acc: 0.8881\n",
      "Epoch 390/400\n",
      "40350/40350 [==============================] - 9s 223us/sample - loss: 0.0166 - acc: 0.9946 - val_loss: 0.6651 - val_acc: 0.8880\n",
      "Epoch 391/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0176 - acc: 0.9938 - val_loss: 0.6717 - val_acc: 0.8884\n",
      "Epoch 392/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0201 - acc: 0.9936 - val_loss: 0.6635 - val_acc: 0.8858\n",
      "Epoch 393/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0173 - acc: 0.9941 - val_loss: 0.6726 - val_acc: 0.8883\n",
      "Epoch 394/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0164 - acc: 0.9945 - val_loss: 0.6763 - val_acc: 0.8863\n",
      "Epoch 395/400\n",
      "40350/40350 [==============================] - 9s 225us/sample - loss: 0.0163 - acc: 0.9945 - val_loss: 0.6745 - val_acc: 0.8879\n",
      "Epoch 396/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0177 - acc: 0.9938 - val_loss: 0.6985 - val_acc: 0.8881\n",
      "Epoch 397/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0194 - acc: 0.9938 - val_loss: 0.6914 - val_acc: 0.8864\n",
      "Epoch 398/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0175 - acc: 0.9938 - val_loss: 0.6857 - val_acc: 0.8872\n",
      "Epoch 399/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0187 - acc: 0.9940 - val_loss: 0.6621 - val_acc: 0.8879\n",
      "Epoch 400/400\n",
      "40350/40350 [==============================] - 9s 224us/sample - loss: 0.0170 - acc: 0.9945 - val_loss: 0.6482 - val_acc: 0.8905\n"
     ]
    }
   ],
   "source": [
    "model = trainModel(builtConditionalModel(drop_out_rate=0.5),[train_headline, train_first_body],[hold_out_headline, hold_out_first_body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60255,
     "status": "ok",
     "timestamp": 1563933488460,
     "user": {
      "displayName": "chuck fu",
      "photoUrl": "",
      "userId": "01740202220584032426"
     },
     "user_tz": 240
    },
    "id": "Gym9dnaryzkk",
    "outputId": "c15c0900-a7dc-4d27-bae3-e571acc63ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional\n",
      "Scores on the test set\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    555    |    11     |    129    |    67     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    62     |    70     |    23     |     7     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    235    |    70     |   1394    |    101    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    170    |    18     |    161    |   6549    |\n",
      "-------------------------------------------------------------\n",
      "Score: 3788.75 out of 4448.5\t(85.16915814319434%)\n",
      "Scores on the test set\n",
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    904    |    22     |    310    |    667    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    215    |    47     |    103    |    332    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    838    |    54     |   2154    |   1418    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |   1104    |    54     |    872    |   16319   |\n",
      "-------------------------------------------------------------\n",
      "Score: 7570.25 out of 11651.25\t(64.9737152666023%)\n"
     ]
    }
   ],
   "source": [
    "print('Conditional')\n",
    "pred = model.predict([hold_out_headline, hold_out_first_body])\n",
    "y_classes = pred.argmax(axis=-1)\n",
    "actual = hold_out_stanceFinal\n",
    "evaluate(y_classes, actual)\n",
    "\n",
    "pred = model.predict([competition_headline, competition_first_body])\n",
    "y_classes = pred.argmax(axis=-1)\n",
    "actual = competition_stanceFinal\n",
    "evaluate(y_classes, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iQtUwECuyz7b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPh9h--sZO-A"
   },
   "outputs": [],
   "source": [
    "h= []\n",
    "b = []\n",
    "pred = model.predict([competition_headline, competition_first_body, competition_last_body])\n",
    "y_classes = pred.argmax(axis=-1)\n",
    "predicted = y_to_stance(y_classes)\n",
    "for stance in competition_dataset.stances:\n",
    "    h.append(stance['Headline'])\n",
    "    b.append(stance['Body ID'])\n",
    "np.savetxt(\"headline.csv\", h, delimiter=\",\",fmt='%s')\n",
    "np.savetxt(\"body_id.csv\", b, delimiter=\",\",fmt='%s')\n",
    "np.savetxt(\"stance.csv\", predicted, delimiter=\",\",fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQiuBiLLa2pZ"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Headline':h,'Body ID':b,'Stance':predicted }).to_csv('/content/drive/My Drive/try/weight_sharing.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ProjectRE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
